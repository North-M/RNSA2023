{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2487e0d3-2db2-4b0e-953a-295d05080a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import pydicom as dicom\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import monai\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monai.networks.nets import EfficientNetBN\n",
    "from monai.networks.nets import ResNet\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b802dd-570e-40c5-96f1-68c17946f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish seeding with seed 344\n",
      "Training on device cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 344\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # Fix the network according to random seed\n",
    "    print('Finish seeding with seed {}'.format(seed))\n",
    "    \n",
    "seed_everything(SEED)\n",
    "print('Training on device {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47bc414-3bca-4e57-9eba-04ca54179ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>middle_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10004</td>\n",
       "      <td>21057</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10005</td>\n",
       "      <td>18667</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10007</td>\n",
       "      <td>47578</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10026</td>\n",
       "      <td>29700</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>4393</td>\n",
       "      <td>9961</td>\n",
       "      <td>2003</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>4394</td>\n",
       "      <td>9961</td>\n",
       "      <td>63032</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>4395</td>\n",
       "      <td>9980</td>\n",
       "      <td>40214</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>4396</td>\n",
       "      <td>9980</td>\n",
       "      <td>40466</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>4397</td>\n",
       "      <td>9983</td>\n",
       "      <td>10806</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  patient_id  series_id  middle_z\n",
       "0         0       10004      21057       128\n",
       "1         1       10004      51033       131\n",
       "2         2       10005      18667       120\n",
       "3         3       10007      47578       127\n",
       "4         4       10026      29700       110\n",
       "...     ...         ...        ...       ...\n",
       "4392   4393        9961       2003       133\n",
       "4393   4394        9961      63032       129\n",
       "4394   4395        9980      40214        94\n",
       "4395   4396        9980      40466       151\n",
       "4396   4397        9983      10806       105\n",
       "\n",
       "[4397 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicom_tag_columns = [\n",
    "    'Columns',\n",
    "    'ImageOrientationPatient',\n",
    "    'ImagePositionPatient',\n",
    "    'InstanceNumber',\n",
    "    'PatientID',\n",
    "    'PatientPosition',\n",
    "    'PixelSpacing',\n",
    "    'RescaleIntercept',\n",
    "    'RescaleSlope',\n",
    "    'Rows',\n",
    "    'SeriesNumber',\n",
    "    'SliceThickness',\n",
    "    'path',\n",
    "    'WindowCenter',\n",
    "    'WindowWidth'\n",
    "]\n",
    "\n",
    "train_dicom_tags = pd.read_parquet('autodl-tmp/train_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "test_dicom_tags = pd.read_parquet('autodl-tmp/test_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "\n",
    "train_series_meta = pd.read_csv('autodl-tmp/train_series_meta.csv')\n",
    "test_series_meta = pd.read_csv('autodl-tmp/test_series_meta.csv')\n",
    "\n",
    "train_csv = pd.read_csv('autodl-tmp/train.csv')\n",
    "\n",
    "mid_z_csv = pd.read_csv('middle_z.csv')\n",
    "\n",
    "complete_series_meta = mid_z_csv[mid_z_csv.middle_z != -1].reset_index()\n",
    "complete_series_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98ed816-e421-4d08-a501-5f5d476d8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_path_gen(patient_id, series_id, train=True):\n",
    "    if(train):\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    else:\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    \n",
    "    path += str(patient_id) + '/' + str(series_id)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def create_3D_scans(folder, downsample_rate=1): \n",
    "    filenames = os.listdir(folder)\n",
    "    filenames = [int(filename.split('.')[0]) for filename in filenames]\n",
    "    filenames = sorted(filenames)\n",
    "    filenames = [str(filename) + '.dcm' for filename in filenames]\n",
    "        \n",
    "    volume = []\n",
    "    #for filename in tqdm(filenames[::downsample_rate], position=0): \n",
    "    for filename in filenames[::downsample_rate]: \n",
    "        filepath = os.path.join(folder, filename)\n",
    "        ds = dicom.dcmread(filepath)\n",
    "        image = ds.pixel_array\n",
    "        \n",
    "        if ds.PixelRepresentation == 1:\n",
    "            bit_shift = ds.BitsAllocated - ds.BitsStored\n",
    "            dtype = image.dtype \n",
    "            image = (image << bit_shift).astype(dtype) >>  bit_shift\n",
    "        \n",
    "        # find rescale params\n",
    "        if (\"RescaleIntercept\" in ds) and (\"RescaleSlope\" in ds):\n",
    "            intercept = float(ds.RescaleIntercept)\n",
    "            slope = float(ds.RescaleSlope)\n",
    "    \n",
    "        # find clipping params\n",
    "        center = int(ds.WindowCenter)\n",
    "        width = int(ds.WindowWidth)\n",
    "        low = center - width / 2\n",
    "        high = center + width / 2    \n",
    "        \n",
    "        \n",
    "        image = (image * slope) + intercept\n",
    "        image = np.clip(image, low, high)\n",
    "\n",
    "        image = (image / np.max(image) * 255).astype(np.int16)\n",
    "        image = image[::downsample_rate, ::downsample_rate]\n",
    "        volume.append( image )\n",
    "    \n",
    "    volume = np.stack(volume, axis=0)\n",
    "    return volume\n",
    "\n",
    "def plot_image_with_seg(volume, volume_seg=[], orientation='Coronal', num_subplots=20):\n",
    "    # simply copy\n",
    "    if len(volume_seg) == 0:\n",
    "        plot_mask = 0\n",
    "    else:\n",
    "        plot_mask = 1\n",
    "        \n",
    "    if orientation == 'Coronal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([1, 0, 2])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([1, 0, 2])\n",
    "        \n",
    "    elif orientation == 'Sagittal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([2, 0, 1])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([2, 0, 1])\n",
    "\n",
    "    elif orientation == 'Axial':\n",
    "        slices = np.linspace(0, volume.shape[0]-1, num_subplots).astype(np.int16)\n",
    "           \n",
    "    rows = np.max( [np.floor(np.sqrt(num_subplots)).astype(int) - 2, 1])\n",
    "    cols = np.ceil(num_subplots/rows).astype(int)\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(cols * 2, rows * 4))\n",
    "    fig.tight_layout(h_pad=0.01, w_pad=0)\n",
    "    \n",
    "    ax = ax.ravel()\n",
    "    for this_ax in ax:\n",
    "        this_ax.axis('off')\n",
    "\n",
    "    for counter, this_slice in enumerate( slices ):\n",
    "        plt.sca(ax[counter])\n",
    "        \n",
    "        image = volume[this_slice, :, :]\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        \n",
    "        if plot_mask:\n",
    "            mask = np.where(volume_seg[this_slice, :, :], volume_seg[this_slice, :, :], np.nan)\n",
    "            plt.imshow(mask, cmap='Set1', alpha=0.5)\n",
    "            \n",
    "def load_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def load_kidney_left_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '/' + 'kidney_left.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def load_kidney_right_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '/' + 'kidney_right.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def load_liver_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '/' + 'liver.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def load_spleen_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '/' + 'liver.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a49d51-e1be-4dcc-9471-f48bb28b7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient_id, series_id = train_series_meta.loc[10, [\"patient_id\", \"series_id\"]].astype('int')\n",
    "# mask_all = load_nii(10721, 63796, root='autodl-tmp/train_mask/')\n",
    "# img_a = load_nii(10721, 63796, root='autodl-tmp/train_images_resample/')\n",
    "\n",
    "# mask_kidney_left = mask_all % 2 == 1\n",
    "# mask_kidney_right = (mask_all // 2) % 2 == 1\n",
    "# mask_liver = (mask_all // 4) % 2 == 1\n",
    "# mask_spleen = (mask_all // 8) % 2 == 1\n",
    "\n",
    "# mask_kls = mask_kidney_left + mask_kidney_right + mask_liver + mask_spleen\n",
    "# mask_z = np.sum(np.sum(mask_kls, 1), 1)\n",
    "# np.argwhere(mask_z)[len(np.argwhere(mask_z)) // 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d051a71-7a1d-4dd4-afe0-2afb02eab363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(mask_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adffe2d8-f9d1-4af6-9872-ff4aee407d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_image_with_seg(mask_kls, orientation='Coronal', num_subplots=7)\n",
    "# plot_image_with_seg(img_a, orientation='Coronal', num_subplots=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa037a1-6ffc-4817-a149-71417beabe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# midz_columns = ['patient_id', 'series_id', 'middle_z']\n",
    "# midz_pd = pd.DataFrame(columns=midz_columns)\n",
    "\n",
    "# for i in tqdm(range(0, len(complete_series_meta))):\n",
    "#     patient_id, series_id = complete_series_meta.loc[i, [\"patient_id\", \"series_id\"]].astype('int')\n",
    "    \n",
    "#     mask_all = load_nii(patient_id, series_id, root='autodl-tmp/train_mask/')\n",
    "#     mask_kidney_left = mask_all % 2 == 1\n",
    "#     mask_kidney_right = (mask_all // 2) % 2 == 1\n",
    "#     mask_liver = (mask_all // 4) % 2 == 1\n",
    "#     mask_spleen = (mask_all // 8) % 2 == 1\n",
    "#     mask_kls = mask_kidney_left + mask_kidney_right + mask_liver + mask_spleen\n",
    "#     mask_z = np.sum(np.sum(mask_kls, 1), 1)\n",
    "#     if np.sum(mask_z) == 0:\n",
    "#         middle_z = -1\n",
    "#     else:\n",
    "#         middle_z = np.argwhere(mask_z)[len(np.argwhere(mask_z)) // 2][0]\n",
    "\n",
    "#     data_out = [[patient_id, series_id, middle_z]]\n",
    "#     pd_out = pd.DataFrame(data=data_out, columns=midz_columns)\n",
    "#     midz_pd = pd.concat([midz_pd, pd_out], axis=0, ignore_index=True)\n",
    "# midz_pd.to_csv('middle_z.csv', index=None)\n",
    "# midz_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17276945-3baf-4f06-be95-57b0b8ae63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "ds = 2\n",
    "\n",
    "midz_pd = pd.read_csv('middle_z.csv')\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, root='autodl-tmp/train_images_resample/', augmentation=False, meta=train_series_meta, device='cpu'):\n",
    "        self.device = device\n",
    "        self.series_meta = meta\n",
    "        self.root = root\n",
    "        self.t = monai.transforms.Compose([monai.transforms.RandZoom(prob=0.5, min_zoom=0.9, max_zoom=1.1),\n",
    "                                           monai.transforms.RandRotate(range_x=3.14 / 24, prob=0.5),\n",
    "                                           monai.transforms.SpatialPad(spatial_size=(320//ds, 280//ds, 280//ds), mode=\"edge\"),\n",
    "                                           monai.transforms.RandSpatialCrop(roi_size=(320//ds, 256//ds, 256//ds), random_size=False),\n",
    "                                           monai.transforms.NormalizeIntensity(divisor = 400)\n",
    "                                ])\n",
    "        self.t_val = monai.transforms.Compose([monai.transforms.NormalizeIntensity(divisor = 400)])\n",
    "        \n",
    "        self.aug = augmentation\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return 1100\n",
    "        return len(self.series_meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        z_aug = random.randint(-12, 12)\n",
    "\n",
    "        patient_id, series_id = self.series_meta.loc[idx, [\"patient_id\", \"series_id\"]].astype('int')\n",
    "        img_a = load_nii(patient_id, series_id, self.root).astype('float32')\n",
    "        \n",
    "        middle_z = midz_pd.loc[midz_pd.series_id == series_id, \"middle_z\"].values[0] // ds\n",
    "        \n",
    "        #img_t = torch.from_numpy(img_a).unsqueeze(0)\n",
    "        #img_t = torch.from_numpy(img_a[::2, ::2, ::2]).unsqueeze(0)\n",
    "        if(self.aug):\n",
    "            img_a = scipy.ndimage.shift(img_a, [z_aug, 0, 0], output=None, order=0, mode='constant', cval=img_a[0, 0, 0])\n",
    "            img_a = np.expand_dims(img_a[::ds, ::ds, ::ds], 0)\n",
    "            img_t = self.t(img_a)\n",
    "            middle_z += z_aug\n",
    "        else:\n",
    "            #img_t = torch.from_numpy(img_a[::ds, ::ds, ::ds]).unsqueeze(0)\n",
    "            img_a = np.expand_dims(img_a[::ds, ::ds, ::ds], 0)\n",
    "            img_t = self.t_val(img_a)\n",
    "\n",
    "        label_t = torch.tensor(middle_z.astype('float32'))\n",
    "        \n",
    "        return img_t, label_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dceba47f-f6ad-43e1-810c-489cf98ff1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, labels = next(iter(train_dl))\n",
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a758474-4610-45f0-953f-9687b8413e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = complete_series_meta[-3200:].reset_index()\n",
    "val_meta = complete_series_meta[0:-3200].reset_index()\n",
    "\n",
    "# train_meta = injury_series_meta[-800:].reset_index()\n",
    "# val_meta = injury_series_meta[0:-800].reset_index()\n",
    "\n",
    "train_ds = CTDataset(meta = train_meta, augmentation=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8)\n",
    "\n",
    "val_ds = CTDataset(meta = val_meta, augmentation=False)\n",
    "val_dl = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1f609bc-2417-4439-b940-0383c9817af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EffNet(nn.Module):\n",
    "    def __init__(self, ch_out=9):\n",
    "        super(EffNet, self).__init__()\n",
    "        self.conv_in = nn.Conv3d(1, 3, kernel_size=5, padding=2, stride=2)\n",
    "        self.net = EfficientNetBN(\"efficientnet-b0\", pretrained=False, progress=False, spatial_dims=3, in_channels=3, num_classes=ch_out,)\n",
    "    def forward(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        #return torch.sigmoid(self.net(x))\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeaf2063-bd15-48c2-a86a-6ca154ac6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def TrainClassifer(model,trn_dl,val_dl,optimizer, scheduler=None,\n",
    "                   n_eopchs=20, device='cpu'):\n",
    " \n",
    "    loss_fn = nn.MSELoss()\n",
    "    model.to(device)\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_val = 999.0\n",
    "    PATH_MODEL = 'Slice/test_slice2.pt'\n",
    "    wandb.init(name='resnet18_test_slice2', \n",
    "               project='ResNet18-slice')\n",
    "\n",
    "    for epoch in range(1, n_eopchs + 1):\n",
    "        loss_train = 0.0\n",
    "        model.train()\n",
    "        for imgs, labels in tqdm(trn_dl, position=0):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs).squeeze(-1)\n",
    "            #outputs = model(imgs.unsqueeze(1))\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        loss_val = 0.0\n",
    "        correct_val = 0.0\n",
    "        model.eval()\n",
    "        \n",
    "        for imgs, labels in tqdm(val_dl):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(imgs).squeeze(-1)\n",
    "                #outputs = model(imgs.unsqueeze(1))\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss_val += loss.item()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "            \n",
    "        if loss_val / len(val_dl) < best_val:\n",
    "            best_val = loss_val / len(val_dl)\n",
    "            torch.save(model.state_dict(), 'model_tmp.pt')\n",
    "            best_model.load_state_dict(torch.load('model_tmp.pt'))\n",
    "            \n",
    "            \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print('{} Eopch {}, Training Loss {}, Val Loss {}'.format(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime()),\n",
    "                                                                  epoch, loss_train / len(trn_dl), loss_val / len(val_dl),))\n",
    "        \n",
    "        \n",
    "        \n",
    "        wandb.log({'training loss': loss_train / len(trn_dl),\n",
    "                  'val loss': loss_val / len(val_dl),})\n",
    "    torch.save(best_model.state_dict(), PATH_MODEL)\n",
    "    print('Finish training: best_val:{}'.format(best_val))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8bd56c3-60ff-4863-95fc-803987a5ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnorthm\u001b[0m (\u001b[33mrsna2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3751ca4389a944089a620adf94a1a4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016672427486628293, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20231005_043323-afxrp1v0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rsna2023/ResNet18-slice/runs/afxrp1v0' target=\"_blank\">resnet18_test_slice2</a></strong> to <a href='https://wandb.ai/rsna2023/ResNet18-slice' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rsna2023/ResNet18-slice' target=\"_blank\">https://wandb.ai/rsna2023/ResNet18-slice</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rsna2023/ResNet18-slice/runs/afxrp1v0' target=\"_blank\">https://wandb.ai/rsna2023/ResNet18-slice/runs/afxrp1v0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:19<00:00,  2.11it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 04:41:06 Eopch 1, Training Loss 628.7015599885583, Val Loss 121.93795802434285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:24<00:00,  2.08it/s]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 04:48:51 Eopch 2, Training Loss 53.320793522354215, Val Loss 28.623952306111654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:16<00:00,  2.12it/s]\n",
      "100%|██████████| 300/300 [01:15<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 04:56:24 Eopch 3, Training Loss 36.79479534905404, Val Loss 27.282227060049774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:11<00:00,  2.15it/s]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 05:03:54 Eopch 4, Training Loss 30.762206713706256, Val Loss 36.48025955279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:13<00:00,  2.14it/s]\n",
      "100%|██████████| 300/300 [01:17<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 05:11:26 Eopch 5, Training Loss 27.159955179337413, Val Loss 31.836952827771505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:18<00:00,  2.12it/s]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 05:19:06 Eopch 6, Training Loss 26.91845420021564, Val Loss 21.30819776189824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:10<00:00,  2.16it/s]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 05:26:38 Eopch 7, Training Loss 25.735823681764305, Val Loss 19.644349741141003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:16<00:00,  2.12it/s]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 05:34:17 Eopch 8, Training Loss 23.551625190377237, Val Loss 21.803604525725046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:20<00:00,  2.10it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 05:41:58 Eopch 9, Training Loss 23.949924967219122, Val Loss 55.27312387307485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:15<00:00,  2.13it/s]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 05:49:37 Eopch 10, Training Loss 22.717095074336974, Val Loss 16.251146466682354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:17<00:00,  2.12it/s]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 05:57:14 Eopch 11, Training Loss 21.385727366060017, Val Loss 24.116958296696346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:22<00:00,  2.09it/s]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 06:04:58 Eopch 12, Training Loss 22.339314028918743, Val Loss 23.253099225362142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:23<00:00,  2.09it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 06:12:42 Eopch 13, Training Loss 20.480616237064822, Val Loss 16.823646647160253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:21<00:00,  2.10it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 06:20:23 Eopch 14, Training Loss 19.885585325844588, Val Loss 21.913222438494365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:15<00:00,  2.13it/s]\n",
      "100%|██████████| 300/300 [01:18<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 06:27:57 Eopch 15, Training Loss 20.568520724372938, Val Loss 18.730131013691427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:15<00:00,  2.13it/s]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 06:35:32 Eopch 16, Training Loss 20.06132139861584, Val Loss 17.04728938281536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:17<00:00,  2.12it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 06:43:10 Eopch 17, Training Loss 17.797496595084667, Val Loss 18.550848133563996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:22<00:00,  2.09it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 06:50:54 Eopch 18, Training Loss 19.101869901791215, Val Loss 22.069849719802537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:17<00:00,  2.12it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 06:58:32 Eopch 19, Training Loss 17.239095314741135, Val Loss 15.877683041468263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:18<00:00,  2.11it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 07:06:11 Eopch 20, Training Loss 17.655551286363043, Val Loss 19.256379655525087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:19<00:00,  2.11it/s]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 07:13:50 Eopch 21, Training Loss 16.612944446988404, Val Loss 23.298984165688356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:15<00:00,  2.13it/s]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 07:21:25 Eopch 22, Training Loss 16.757467159442605, Val Loss 30.133903932174047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:20<00:00,  2.10it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 07:29:06 Eopch 23, Training Loss 16.85791667321697, Val Loss 20.362948358953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:20<00:00,  2.10it/s]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 07:36:48 Eopch 24, Training Loss 15.74138745892793, Val Loss 19.694037202795347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:21<00:00,  2.10it/s]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 07:44:32 Eopch 25, Training Loss 15.810167119428515, Val Loss 16.54695967311971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:19<00:00,  2.11it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 07:52:12 Eopch 26, Training Loss 16.087306949691847, Val Loss 17.072936187585196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:16<00:00,  2.12it/s]\n",
      "100%|██████████| 300/300 [01:20<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 07:59:49 Eopch 27, Training Loss 14.73094510352239, Val Loss 16.148107617273926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:18<00:00,  2.11it/s]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 08:07:27 Eopch 28, Training Loss 13.363643765053713, Val Loss 16.580306245411435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:14<00:00,  2.14it/s]\n",
      "100%|██████████| 300/300 [01:23<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 08:15:06 Eopch 29, Training Loss 14.423625068883412, Val Loss 15.119095928023258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [06:17<00:00,  2.12it/s]\n",
      "100%|██████████| 300/300 [01:21<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 08:22:45 Eopch 30, Training Loss 14.084296721015125, Val Loss 18.15269568512837\n",
      "Finish training: best_val:15.119095928023258\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val loss</td><td>█▂▂▂▂▁▁▁▄▁▂▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>14.0843</td></tr><tr><td>val loss</td><td>18.1527</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_test_slice2</strong> at: <a href='https://wandb.ai/rsna2023/ResNet18-slice/runs/afxrp1v0' target=\"_blank\">https://wandb.ai/rsna2023/ResNet18-slice/runs/afxrp1v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231005_043323-afxrp1v0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = ResNet(block='basic', layers=[2, 2, 2, 2], block_inplanes=[64, 128, 256, 512],\n",
    "            spatial_dims=3, n_input_channels=1, num_classes=1, conv1_t_stride=4).to(device)\n",
    "# net = EffNet(ch_out=1).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr=2e-4)\n",
    "TrainClassifer(model=net,trn_dl=train_dl,val_dl=val_dl,optimizer=optimizer, \n",
    "               scheduler=None, n_eopchs=30, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8b7e658-5a8b-44a9-ab1a-e27126e3c3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:18<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.988916\n",
      "1.5932526230812072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = ResNet(block='basic', layers=[2, 2, 2, 2], block_inplanes=[64, 128, 256, 512],\n",
    "            spatial_dims=3, n_input_channels=1, num_classes=1, conv1_t_stride=4).to(device)\n",
    "net.load_state_dict(torch.load('Slice/test_slice1.pt'))\n",
    "\n",
    "max_diff = 0\n",
    "mean_diff = 0\n",
    "loss_fn = nn.MSELoss()\n",
    "net.eval()\n",
    "for imgs, labels in tqdm(val_dl):\n",
    "    with torch.no_grad():\n",
    "        preds = net(imgs.to(device))\n",
    "        diff = preds.squeeze(-1) - labels.to(device)\n",
    "        #print(diff)\n",
    "        diff = diff.to('cpu').detach().numpy()\n",
    "        diff = np.mean(np.abs(diff))\n",
    "        #print(diff)\n",
    "        max_diff = max(diff, max_diff)\n",
    "        #diff = loss_fn(preds.squeeze(-1), labels.to(device))\n",
    "        #print(diff)\n",
    "        mean_diff += diff\n",
    "print(max_diff)\n",
    "print(mean_diff / len(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99d43b-a201-49b1-bac2-ffe502770635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a6c36-c625-450f-9fa0-b0ab85320308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
