{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf32a2a-7118-4d81-b093-818e344d05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import pydicom as dicom\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import monai\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monai.networks.nets import EfficientNetBN\n",
    "from monai.networks.nets import ResNet\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "import timm\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a795ca56-6bcd-4967-b375-dc59214d526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish seeding with seed 344\n",
      "Training on device cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 344\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # Fix the network according to random seed\n",
    "    print('Finish seeding with seed {}'.format(seed))\n",
    "    \n",
    "seed_everything(SEED)\n",
    "print('Training on device {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a8a495-8bee-478e-a16b-0e27bfd70da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "      <th>any_injury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>9951</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>9960</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>9961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>9980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>9983</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3147 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0          10004              1             0                      0   \n",
       "1          10005              1             0                      1   \n",
       "2          10007              1             0                      1   \n",
       "3          10026              1             0                      1   \n",
       "4          10051              1             0                      1   \n",
       "...          ...            ...           ...                    ...   \n",
       "3142        9951              1             0                      1   \n",
       "3143        9960              1             0                      1   \n",
       "3144        9961              1             0                      1   \n",
       "3145        9980              1             0                      1   \n",
       "3146        9983              1             0                      1   \n",
       "\n",
       "      extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0                        1               0           1            0   \n",
       "1                        0               1           0            0   \n",
       "2                        0               1           0            0   \n",
       "3                        0               1           0            0   \n",
       "4                        0               1           0            0   \n",
       "...                    ...             ...         ...          ...   \n",
       "3142                     0               1           0            0   \n",
       "3143                     0               1           0            0   \n",
       "3144                     0               1           0            0   \n",
       "3145                     0               1           0            0   \n",
       "3146                     0               1           0            0   \n",
       "\n",
       "      liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0                 1          0           0               0           0   \n",
       "1                 1          0           0               1           0   \n",
       "2                 1          0           0               1           0   \n",
       "3                 1          0           0               1           0   \n",
       "4                 1          0           0               0           1   \n",
       "...             ...        ...         ...             ...         ...   \n",
       "3142              1          0           0               1           0   \n",
       "3143              1          0           0               1           0   \n",
       "3144              1          0           0               1           0   \n",
       "3145              1          0           0               0           0   \n",
       "3146              1          0           0               0           0   \n",
       "\n",
       "      spleen_high  any_injury  \n",
       "0               1           1  \n",
       "1               0           0  \n",
       "2               0           0  \n",
       "3               0           0  \n",
       "4               0           1  \n",
       "...           ...         ...  \n",
       "3142            0           0  \n",
       "3143            0           0  \n",
       "3144            0           0  \n",
       "3145            1           1  \n",
       "3146            1           1  \n",
       "\n",
       "[3147 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicom_tag_columns = [\n",
    "    'Columns',\n",
    "    'ImageOrientationPatient',\n",
    "    'ImagePositionPatient',\n",
    "    'InstanceNumber',\n",
    "    'PatientID',\n",
    "    'PatientPosition',\n",
    "    'PixelSpacing',\n",
    "    'RescaleIntercept',\n",
    "    'RescaleSlope',\n",
    "    'Rows',\n",
    "    'SeriesNumber',\n",
    "    'SliceThickness',\n",
    "    'path',\n",
    "    'WindowCenter',\n",
    "    'WindowWidth'\n",
    "]\n",
    "\n",
    "train_dicom_tags = pd.read_parquet('autodl-tmp/train_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "test_dicom_tags = pd.read_parquet('autodl-tmp/test_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "\n",
    "train_series_meta = pd.read_csv('autodl-tmp/train_series_meta.csv')\n",
    "test_series_meta = pd.read_csv('autodl-tmp/test_series_meta.csv')\n",
    "\n",
    "train_csv = pd.read_csv('autodl-tmp/train.csv')\n",
    "\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b75b036-35cc-4f07-9480-1d2ff2ab6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_series_meta = train_series_meta.loc[train_series_meta.patient_id.isin(train_csv.loc[train_csv.any_injury == 1, \"patient_id\"].values)]\n",
    "healthy_series_meta = train_series_meta.loc[train_series_meta.patient_id.isin(train_csv.loc[train_csv.any_injury == 0, \"patient_id\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7096cd30-8868-4b07-b313-ea7cfce8fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_path_gen(patient_id, series_id, train=True):\n",
    "    if(train):\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    else:\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    \n",
    "    path += str(patient_id) + '/' + str(series_id)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def create_3D_scans(folder, downsample_rate=1): \n",
    "    filenames = os.listdir(folder)\n",
    "    filenames = [int(filename.split('.')[0]) for filename in filenames]\n",
    "    filenames = sorted(filenames)\n",
    "    filenames = [str(filename) + '.dcm' for filename in filenames]\n",
    "        \n",
    "    volume = []\n",
    "    #for filename in tqdm(filenames[::downsample_rate], position=0): \n",
    "    for filename in filenames[::downsample_rate]: \n",
    "        filepath = os.path.join(folder, filename)\n",
    "        ds = dicom.dcmread(filepath)\n",
    "        image = ds.pixel_array\n",
    "        \n",
    "        if ds.PixelRepresentation == 1:\n",
    "            bit_shift = ds.BitsAllocated - ds.BitsStored\n",
    "            dtype = image.dtype \n",
    "            image = (image << bit_shift).astype(dtype) >>  bit_shift\n",
    "        \n",
    "        # find rescale params\n",
    "        if (\"RescaleIntercept\" in ds) and (\"RescaleSlope\" in ds):\n",
    "            intercept = float(ds.RescaleIntercept)\n",
    "            slope = float(ds.RescaleSlope)\n",
    "    \n",
    "        # find clipping params\n",
    "        center = int(ds.WindowCenter)\n",
    "        width = int(ds.WindowWidth)\n",
    "        low = center - width / 2\n",
    "        high = center + width / 2    \n",
    "        \n",
    "        \n",
    "        image = (image * slope) + intercept\n",
    "        image = np.clip(image, low, high)\n",
    "\n",
    "        image = (image / np.max(image) * 255).astype(np.int16)\n",
    "        image = image[::downsample_rate, ::downsample_rate]\n",
    "        volume.append( image )\n",
    "    \n",
    "    volume = np.stack(volume, axis=0)\n",
    "    return volume\n",
    "\n",
    "def plot_image_with_seg(volume, volume_seg=[], orientation='Coronal', num_subplots=20):\n",
    "    # simply copy\n",
    "    if len(volume_seg) == 0:\n",
    "        plot_mask = 0\n",
    "    else:\n",
    "        plot_mask = 1\n",
    "        \n",
    "    if orientation == 'Coronal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([1, 0, 2])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([1, 0, 2])\n",
    "        \n",
    "    elif orientation == 'Sagittal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([2, 0, 1])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([2, 0, 1])\n",
    "\n",
    "    elif orientation == 'Axial':\n",
    "        slices = np.linspace(0, volume.shape[0]-1, num_subplots).astype(np.int16)\n",
    "           \n",
    "    rows = np.max( [np.floor(np.sqrt(num_subplots)).astype(int) - 2, 1])\n",
    "    cols = np.ceil(num_subplots/rows).astype(int)\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(cols * 2, rows * 4))\n",
    "    fig.tight_layout(h_pad=0.01, w_pad=0)\n",
    "    \n",
    "    ax = ax.ravel()\n",
    "    for this_ax in ax:\n",
    "        this_ax.axis('off')\n",
    "\n",
    "    for counter, this_slice in enumerate( slices ):\n",
    "        plt.sca(ax[counter])\n",
    "        \n",
    "        image = volume[this_slice, :, :]\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        \n",
    "        if plot_mask:\n",
    "            mask = np.where(volume_seg[this_slice, :, :], volume_seg[this_slice, :, :], np.nan)\n",
    "            plt.imshow(mask, cmap='Set1', alpha=0.5)\n",
    "            \n",
    "def load_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2141f4ef-37c8-4cef-b89d-7ff9a539c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = 2\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, root='autodl-tmp/train_images_resample/', augmentation=False, meta=train_series_meta, device='cpu'):\n",
    "        self.device = device\n",
    "        self.series_meta = meta\n",
    "        self.root = root\n",
    "        self.t = monai.transforms.Compose([monai.transforms.RandZoom(prob=0.5, min_zoom=0.9, max_zoom=1.1),\n",
    "                                           monai.transforms.RandRotate(range_x=3.14 / 24, prob=0.5),\n",
    "                                           monai.transforms.SpatialPad(spatial_size=(320//ds, 280//ds, 280//ds), mode=\"edge\"),\n",
    "                                           monai.transforms.RandSpatialCrop(roi_size=(320//ds, 256//ds, 256//ds), random_size=False),\n",
    "                                           monai.transforms.NormalizeIntensity(divisor = 400)\n",
    "                                ])\n",
    "        self.t_val = monai.transforms.Compose([monai.transforms.NormalizeIntensity(divisor = 400)])\n",
    "        \n",
    "        self.aug = augmentation\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return 1100\n",
    "        return len(self.series_meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        patient_id, series_id = self.series_meta.loc[idx, [\"patient_id\", \"series_id\"]].astype('int')\n",
    "        img_a = load_nii(patient_id, series_id, self.root).astype('float32')\n",
    "        #img_t = torch.from_numpy(img_a).unsqueeze(0)\n",
    "        #img_t = torch.from_numpy(img_a[::2, ::2, ::2]).unsqueeze(0)\n",
    "        if(self.aug):\n",
    "            img_t = self.t(np.expand_dims(img_a[::ds, ::ds, ::ds], 0))\n",
    "        else:\n",
    "            #img_t = torch.from_numpy(img_a[::ds, ::ds, ::ds]).unsqueeze(0)\n",
    "            img_t = self.t_val(np.expand_dims(img_a[::ds, ::ds, ::ds], 0))\n",
    "        label_columns = [\n",
    "            'bowel_healthy',\n",
    "            'bowel_injury',\n",
    "            'extravasation_healthy',\n",
    "            'extravasation_injury',\n",
    "            'kidney_healthy',\n",
    "            'kidney_low',\n",
    "            'kidney_high',\n",
    "            'liver_healthy',\n",
    "            'liver_low',\n",
    "            'liver_high',\n",
    "            'spleen_healthy',\n",
    "            'spleen_low',\n",
    "            'spleen_high',\n",
    "            #'any_injury'\n",
    "        ]\n",
    "        label_a = train_csv.loc[train_csv.patient_id == patient_id, label_columns].values[0].astype('float32')\n",
    "        label_t = torch.from_numpy(label_a)\n",
    "        return img_t, label_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd90d76-a251-4d2d-9667-6b4c23550672",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = train_series_meta[-3600:].reset_index()\n",
    "val_meta = train_series_meta[0:-3600].reset_index()\n",
    "\n",
    "# train_meta = injury_series_meta[-800:].reset_index()\n",
    "# val_meta = injury_series_meta[0:-800].reset_index()\n",
    "\n",
    "train_ds = CTDataset(meta = train_meta, augmentation=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8)\n",
    "\n",
    "val_ds = CTDataset(meta = val_meta, augmentation=False)\n",
    "val_dl = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1f0a1d-e6aa-4575-b1f1-5efd4457a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EffNet(nn.Module):\n",
    "#     def __init__(self, ch_out=9):\n",
    "#         super(EffNet, self).__init__()\n",
    "#         #self.conv_in = nn.Conv3d(1, 3, kernel_size=5, padding=2, stride=2)\n",
    "#         self.net = EfficientNetBN(\"efficientnet-b0\", pretrained=False, progress=False, spatial_dims=3, in_channels=1, num_classes=ch_out,)\n",
    "#     def forward(self, x):\n",
    "#         #x = self.conv_in(x)\n",
    "#         #return torch.sigmoid(self.net(x))\n",
    "#         return self.net(x)\n",
    "\n",
    "class FullVolNet(nn.Module):\n",
    "    def __init__(self, backbone = \"tf_efficientnetv2_s.in21k_ft_in1k\", \n",
    "                 ch_in = 3, ch_out = 9, slices = 15, dropout = 0.0, pretrained=True):\n",
    "        super(FullVolNet, self).__init__()\n",
    "        self.slices = slices\n",
    "        \n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=ch_in,\n",
    "            num_classes=ch_out,\n",
    "            features_only=False,\n",
    "            drop_rate=0.0,\n",
    "            drop_path_rate=0.0,\n",
    "            pretrained=False,\n",
    "        )\n",
    "        \n",
    "        if pretrained:\n",
    "            self.encoder.load_state_dict(torch.load('pretrained/tf_efficientnetv2_s.in21k_ft_in1k_13class.pt'))\n",
    "        \n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "        \n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=0.0, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, ch_out),\n",
    "        )\n",
    "        \n",
    "        self.head2 = nn.Conv1d(slices, 1, 1)\n",
    "        \n",
    "        \n",
    "    def slicer(self, img, slices):\n",
    "        #img = img.squeeze(1)\n",
    "        z_length = img.shape[-3]\n",
    "        z_slices = (np.linspace(0, z_length, slices + 4)).astype('int')\n",
    "        z_slices = z_slices[2:-2]\n",
    "        #print(z_slices)\n",
    "        slices_list = []\n",
    "        for z in z_slices:\n",
    "            slices_list.append(img[:, :, z-1:z+2, :, :])\n",
    "        img_slice = torch.cat(slices_list, 1)\n",
    "        return img_slice\n",
    "        \n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        x = self.slicer(x, self.slices)\n",
    "        bs, nslice,ch, sz1, sz2 = x.shape\n",
    "        x = x.view(bs*nslice, ch, sz1, sz2)\n",
    "        \n",
    "        feature_2d = self.encoder(x)\n",
    "        feature_2d = feature_2d.view(bs, nslice, -1)\n",
    "        \n",
    "        feature_lstm, _ = self.lstm(feature_2d)\n",
    "        feature_lstm = feature_lstm.contiguous().view(bs * nslice, -1)\n",
    "        \n",
    "        preds = self.head(feature_lstm)\n",
    "        preds = preds.view(bs, nslice, -1).contiguous()\n",
    "        preds = self.head2(preds)\n",
    "        \n",
    "        return preds.squeeze(1)\n",
    "        \n",
    "        \n",
    "        # bs = x.shape[0]\n",
    "        # x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
    "        # feat = self.encoder(x)\n",
    "        # feat = feat.view(bs, n_slice_per_c, -1)\n",
    "        # feat, _ = self.lstm(feat)\n",
    "        # feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        # feat = self.head(feat)\n",
    "        # feat = feat.view(bs, n_slice_per_c).contiguous()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b95491b-07eb-45ea-90f6-456377057226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, labels = next(iter(train_dl))\n",
    "# net = FullVolNet(ch_out = 13)\n",
    "# img_s = net(imgs)\n",
    "# img_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af7441f-f99e-44ef-8e67-11273ff4ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "\n",
    "def transform_9class(label_in):\n",
    "    label_out = [1 - label_in[0],\n",
    "                   label_in[0],\n",
    "                    1- label_in[1],\n",
    "                   label_in[1],\n",
    "                   (1 - label_in[2]) * (1 - label_in[3]),\n",
    "                   label_in[2],\n",
    "                   label_in[3],\n",
    "                   (1 - label_in[4]) * (1 - label_in[5]),\n",
    "                    label_in[4],\n",
    "                   label_in[5],\n",
    "                   (1 - label_in[6]) * (1 - label_in[7]),\n",
    "                   label_in[6],\n",
    "                   label_in[7]]\n",
    "    return label_out\n",
    "\n",
    "def transform_13class(label_in):\n",
    "    label_out = label_in\n",
    "    return label_out.tolist()\n",
    "\n",
    "def transform_13class_crossentropy(label_in):\n",
    "    bowl_label = label_in[0:2]\n",
    "    extravasation_label = label_in[2:4]\n",
    "    kidney_label = label_in[4:7]\n",
    "    liver_label = label_in[7:10]\n",
    "    spleen_label = label_in[10:13]\n",
    "    \n",
    "    label_in[0:2] = softmax(bowl_label)\n",
    "    label_in[2:4] = softmax(extravasation_label)\n",
    "    label_in[4:7] = softmax(kidney_label)\n",
    "    label_in[7:10] = softmax(liver_label)\n",
    "    label_in[10:13] = softmax(spleen_label)\n",
    "    \n",
    "    \n",
    "    label_out = label_in\n",
    "    return label_out.tolist()\n",
    "\n",
    "\n",
    "def loss_metrics(metrics, transform):\n",
    "    preds = [transform(x) for x in metrics[\"predict\"]]\n",
    "    targets = [x.tolist() for x in metrics[\"label\"]]\n",
    "    targets_any_injury = metrics[\"label\"][:, -1]\n",
    "    \n",
    "    loss_list = []\n",
    "    #print(metrics)\n",
    "    print(\"F1 score: \", sklearn.metrics.f1_score(metrics[\"label\"], np.around(metrics[\"predict\"]), average=None, zero_division=0.0))\n",
    "    print(\"AUC score: \", sklearn.metrics.roc_auc_score(metrics[\"label\"], metrics[\"predict\"], average=None))\n",
    "    \n",
    "    for i in range(0, len(preds)):\n",
    "        predict = preds[i]\n",
    "        target = targets[i]\n",
    "        \n",
    "        label_pred = np.zeros(14)\n",
    "        label_pred[0] = predict[0] / (predict[0] + predict[1])\n",
    "        label_pred[1] = predict[1] / (predict[0] + predict[1])\n",
    "        label_pred[2] = predict[2] / (predict[2] + predict[3])\n",
    "        label_pred[3] = predict[3] / (predict[2] + predict[3])\n",
    "        label_pred[4] = predict[4] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[5] = predict[5] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[6] = predict[6] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[7] = predict[7] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[8] = predict[8] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[9] = predict[9] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[10] = predict[10] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[11] = predict[11] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[12] = predict[12] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[13] = max([1 - label_pred[x] for x in [0, 2, 4, 7, 10]])\n",
    "        \n",
    "        targets_any_injury = max([1 - target[x] for x in [0, 2, 4, 7, 10]])\n",
    "        \n",
    "        target.append(targets_any_injury)\n",
    "        label_target = np.array(target)\n",
    "        \n",
    "        weight = np.array([1, 2, 1, 6, 1, 2, 4, 1, 2, 4, 1, 2, 4, 6])\n",
    "        \n",
    "        loss_list.append(sklearn.metrics.log_loss(\n",
    "            y_true=label_target,\n",
    "            y_pred=label_pred,\n",
    "            sample_weight=weight))\n",
    "    #print(\"Weighted Loss: \" + np.mean(loss_list))\n",
    "    \n",
    "    return np.mean(loss_list)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #print(np.array(preds).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc4c8d8-bcaf-457a-a88e-48e6d3bdb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def loss_fn(outputs, labels):\n",
    "    bowl_label = labels[:, 0:2]\n",
    "    bowl_pred = outputs[:, 0:2]\n",
    "    extravasation_label = labels[:, 2:4]\n",
    "    extravasation_pred = outputs[:, 2:4]\n",
    "    kidney_label = labels[:, 4:7]\n",
    "    kidney_pred = outputs[:, 4:7]\n",
    "    liver_label = labels[:, 7:10]\n",
    "    liver_pred = outputs[:, 7:10]\n",
    "    spleen_label = labels[:, 10:13]\n",
    "    spleen_pred = outputs[:, 10:13]\n",
    "    \n",
    "    loss_bowl = nn.CrossEntropyLoss(weight=torch.Tensor([0.033, 0.967]).to(device))\n",
    "    loss_extravasation = nn.CrossEntropyLoss(weight=torch.Tensor([0.056, 0.944]).to(device))\n",
    "    # loss_bowl = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1, 10]).to(device))\n",
    "    # loss_extravasation = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1, 5]).to(device))\n",
    "    loss_kidney = nn.CrossEntropyLoss(weight=torch.Tensor([0.016, 0.492, 0.492]).to(device))\n",
    "    loss_liver = nn.CrossEntropyLoss(weight=torch.Tensor([0.027, 0.487, 0.487]).to(device))\n",
    "    loss_spleen = nn.CrossEntropyLoss(weight=torch.Tensor([0.027, 0.487, 0.487]).to(device))\n",
    "    # loss_bowl = nn.BCEWithLogitsLoss()\n",
    "    # loss_extravasation = nn.BCEWithLogitsLoss()\n",
    "    # loss_kidney = nn.CrossEntropyLoss()\n",
    "    # loss_liver = nn.CrossEntropyLoss()\n",
    "    # loss_spleen = nn.CrossEntropyLoss()\n",
    "    \n",
    "    loss = (loss_bowl(bowl_pred, bowl_label) + \n",
    "            loss_extravasation(extravasation_pred, extravasation_label) + \n",
    "            loss_kidney(kidney_pred, kidney_label) + \n",
    "            loss_liver(liver_pred, liver_label) + \n",
    "            loss_spleen(spleen_pred, spleen_label))\n",
    "    return loss\n",
    "\n",
    "def TrainClassifer(model,trn_dl,val_dl,optimizer, scheduler=None,\n",
    "                   n_eopchs=20, device='cpu'):\n",
    " \n",
    "    #loss_fn = nn.BCELoss(weight=torch.Tensor([1, 6, 1, 6, 1, 4, 8, 1, 4, 8, 1, 4, 8]).to(device))\n",
    "    #loss_fn = nn.BCELoss()\n",
    "    # loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1, 30, 1, 15, 1, 30, 30, 1, 18, 18, 1, 18, 18]).to(device))\n",
    "    model.to(device)\n",
    "    best_model = copy.deepcopy(model)\n",
    "    bestweight_model = copy.deepcopy(model)\n",
    "    best_val = 999.0\n",
    "    best_weightloss = 999.0\n",
    "    metrics = {'predict': [], 'label' : []}\n",
    "    PATH_MODEL = 'FullVol2.5D/FullVol2.5D_Effnetv2_13class_crossentropy_posweight_bestloss.pt'\n",
    "    PATH_MODEL2 = 'FullVol2.5D/FullVol2.5D_Effnetv2_13class_crossentropy_posweight_bestmetric.pt'\n",
    "    wandb.init(name='FullVol2.5D_Effnetv2_13class_crossentropy_posweight', \n",
    "               project='FullVol2.5D_crossentropy')\n",
    "\n",
    "    for epoch in range(1, n_eopchs + 1):\n",
    "        loss_train = 0.0\n",
    "        model.train()\n",
    "        for imgs, labels in tqdm(trn_dl, position=0):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            #outputs = model(imgs.unsqueeze(1))\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        loss_val = 0.0\n",
    "        correct_val = 0.0\n",
    "        model.eval()\n",
    "        \n",
    "        for imgs, labels in tqdm(val_dl):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(imgs)\n",
    "                #outputs = model(imgs.unsqueeze(1))\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss_val += loss.item()\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "                metrics['predict'].extend((outputs.to('cpu').detach().numpy()).tolist())\n",
    "                metrics['label'].extend((labels.to('cpu').detach().numpy()).tolist())\n",
    "        \n",
    "        metrics['predict'] = np.array(metrics['predict'])\n",
    "        #metrics['predict'] = np.array([[0.5, 0.5, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333]]*len(metrics['label']))\n",
    "        metrics['label'] = np.array(metrics['label'])\n",
    "        weighted_loss = loss_metrics(metrics, transform_13class_crossentropy)\n",
    "        metrics = {'predict': [], 'label' : []}\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if (weighted_loss) < best_weightloss:\n",
    "            best_weightloss = weighted_loss\n",
    "            torch.save(model.state_dict(), 'model_tmp.pt')\n",
    "            bestweight_model.load_state_dict(torch.load('model_tmp.pt'))\n",
    "            \n",
    "        if loss_val / len(val_dl) < best_val:\n",
    "            best_val = loss_val / len(val_dl)\n",
    "            torch.save(model.state_dict(), 'model_tmp.pt')\n",
    "            best_model.load_state_dict(torch.load('model_tmp.pt'))\n",
    "            \n",
    "            \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print('{} Eopch {}, Training Loss {}, Val Loss {}, Weighted Loss {}'.format(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime()),\n",
    "                                                                  epoch, loss_train / len(trn_dl), loss_val / len(val_dl),\n",
    "                                                                                     weighted_loss))\n",
    "        \n",
    "        \n",
    "        \n",
    "        wandb.log({'training loss': loss_train / len(trn_dl),\n",
    "                  'val loss': loss_val / len(val_dl),\n",
    "                  'weighted loss': weighted_loss})\n",
    "    torch.save(best_model.state_dict(), PATH_MODEL)\n",
    "    torch.save(bestweight_model.state_dict(), PATH_MODEL2)\n",
    "    print('Finish training: best_val:{}, best_weighted loss:{}'.format(best_val, best_weightloss))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "732ea298-acdd-451a-8881-b6f393a121e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnorthm\u001b[0m (\u001b[33mrsna2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7ec0192a54c3dbd4e252f93d59c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670243224749963, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20230923_234705-3wvws69o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rsna2023/FullVol2.5D_crossentropy/runs/3wvws69o' target=\"_blank\">FullVol2.5D_Effnetv2_13class_crossentropy_posweight-3-</a></strong> to <a href='https://wandb.ai/rsna2023/FullVol2.5D_crossentropy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rsna2023/FullVol2.5D_crossentropy' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5D_crossentropy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rsna2023/FullVol2.5D_crossentropy/runs/3wvws69o' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5D_crossentropy/runs/3wvws69o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [05:02<00:00,  2.98it/s]\n",
      "100%|██████████| 278/278 [01:10<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.98585121 0.         0.96410256 0.         0.         0.\n",
      " 0.         0.02390438 0.         0.         0.         0.\n",
      " 0.        ]\n",
      "AUC score:  [0.66253426 0.66253426 0.56190778 0.56190778 0.62110682 0.58015836\n",
      " 0.68173432 0.66786392 0.64794863 0.57431959 0.66955188 0.5737817\n",
      " 0.73898877]\n",
      "2023-09-23 23:53:24 Eopch 1, Training Loss 5.399667580127716, Val Loss 5.812158021781085, Weighted Loss 0.5344237083345988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [05:00<00:00,  3.00it/s]\n",
      "100%|██████████| 278/278 [01:09<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.98399634 0.         0.9606373  0.04545455 0.00192864 0.\n",
      " 0.         0.04916421 0.         0.         0.         0.\n",
      " 0.        ]\n",
      "AUC score:  [0.72085538 0.72085538 0.6596062  0.6596062  0.71592021 0.66358968\n",
      " 0.76127511 0.72446801 0.65936446 0.75543374 0.72556287 0.62057773\n",
      " 0.80908406]\n",
      "2023-09-23 23:59:36 Eopch 2, Training Loss 4.897245116763645, Val Loss 5.468149639290871, Weighted Loss 0.5312898828869189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [05:03<00:00,  2.97it/s]\n",
      "100%|██████████| 278/278 [01:11<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.96674473 0.18390805 0.92277615 0.10227273 0.03787879 0.\n",
      " 0.         0.03366337 0.         0.         0.00206186 0.\n",
      " 0.        ]\n",
      "AUC score:  [0.70772516 0.70772516 0.6868187  0.6868187  0.73010296 0.63574004\n",
      " 0.84389094 0.760123   0.64464033 0.77503346 0.7395311  0.59785784\n",
      " 0.85232669]\n",
      "2023-09-24 00:05:53 Eopch 3, Training Loss 4.424793926808569, Val Loss 5.608411666086252, Weighted Loss 0.5458571132410981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [05:01<00:00,  2.99it/s]\n",
      "100%|██████████| 278/278 [01:08<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97689464 0.13793103 0.95508274 0.11214953 0.07249071 0.\n",
      " 0.         0.23872679 0.         0.         0.20994475 0.\n",
      " 0.03389831]\n",
      "AUC score:  [0.74864555 0.74864555 0.71552247 0.71552247 0.72265122 0.60916431\n",
      " 0.666325   0.72218081 0.66438133 0.68630888 0.77597785 0.674097\n",
      " 0.85825392]\n",
      "2023-09-24 00:12:05 Eopch 4, Training Loss 4.074992394049962, Val Loss 5.676379913799197, Weighted Loss 0.5035257582031708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [04:59<00:00,  3.01it/s]\n",
      "100%|██████████| 278/278 [01:11<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97540603 0.20895522 0.92692496 0.18579235 0.19180471 0.\n",
      " 0.         0.35197368 0.         0.         0.1835206  0.\n",
      " 0.12903226]\n",
      "AUC score:  [0.75584805 0.75584805 0.70414654 0.70414654 0.75093951 0.65179131\n",
      " 0.73882739 0.71866529 0.6464686  0.73006565 0.79238797 0.64937173\n",
      " 0.88324   ]\n",
      "2023-09-24 00:18:18 Eopch 5, Training Loss 3.630981887512737, Val Loss 5.736940015187796, Weighted Loss 0.4952643229589958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 554/900 [03:09<01:58,  2.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m net \u001b[38;5;241m=\u001b[39m FullVolNet(ch_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m13\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mTrainClassifer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrn_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eopchs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mTrainClassifer\u001b[0;34m(model, trn_dl, val_dl, optimizer, scheduler, n_eopchs, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[1;32m     62\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 63\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     65\u001b[0m loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:355\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/overrides.py:1394\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1388\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1389\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in PyTorch 1.11, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1390\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1394\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/data/meta_tensor.py:276\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 276\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:1142\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = FullVolNet(ch_out = 13).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-5)\n",
    "TrainClassifer(model=net,trn_dl=train_dl,val_dl=val_dl,optimizer=optimizer, \n",
    "               scheduler=None, n_eopchs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bc94f-0d72-4b4c-b57f-36258115f63d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
