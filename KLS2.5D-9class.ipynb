{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290beb39-046d-4947-ba9b-d65ac0af40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import pydicom as dicom\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import monai\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monai.networks.nets import EfficientNetBN\n",
    "from monai.networks.nets import ResNet\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "import timm\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498ba35a-469a-4117-b37f-fb6eeaa323a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish seeding with seed 344\n",
      "Training on device cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 344\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # Fix the network according to random seed\n",
    "    print('Finish seeding with seed {}'.format(seed))\n",
    "    \n",
    "seed_everything(SEED)\n",
    "print('Training on device {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f1c59e-d587-48fb-ba83-3ac818874299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>middle_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10004</td>\n",
       "      <td>21057</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10005</td>\n",
       "      <td>18667</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10007</td>\n",
       "      <td>47578</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10026</td>\n",
       "      <td>29700</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>4393</td>\n",
       "      <td>9961</td>\n",
       "      <td>2003</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>4394</td>\n",
       "      <td>9961</td>\n",
       "      <td>63032</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>4395</td>\n",
       "      <td>9980</td>\n",
       "      <td>40214</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>4396</td>\n",
       "      <td>9980</td>\n",
       "      <td>40466</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>4397</td>\n",
       "      <td>9983</td>\n",
       "      <td>10806</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  patient_id  series_id  middle_z\n",
       "0         0       10004      21057       128\n",
       "1         1       10004      51033       131\n",
       "2         2       10005      18667       120\n",
       "3         3       10007      47578       127\n",
       "4         4       10026      29700       110\n",
       "...     ...         ...        ...       ...\n",
       "4392   4393        9961       2003       133\n",
       "4393   4394        9961      63032       129\n",
       "4394   4395        9980      40214        94\n",
       "4395   4396        9980      40466       151\n",
       "4396   4397        9983      10806       105\n",
       "\n",
       "[4397 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicom_tag_columns = [\n",
    "    'Columns',\n",
    "    'ImageOrientationPatient',\n",
    "    'ImagePositionPatient',\n",
    "    'InstanceNumber',\n",
    "    'PatientID',\n",
    "    'PatientPosition',\n",
    "    'PixelSpacing',\n",
    "    'RescaleIntercept',\n",
    "    'RescaleSlope',\n",
    "    'Rows',\n",
    "    'SeriesNumber',\n",
    "    'SliceThickness',\n",
    "    'path',\n",
    "    'WindowCenter',\n",
    "    'WindowWidth'\n",
    "]\n",
    "\n",
    "train_dicom_tags = pd.read_parquet('autodl-tmp/train_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "test_dicom_tags = pd.read_parquet('autodl-tmp/test_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "\n",
    "train_series_meta = pd.read_csv('autodl-tmp/train_series_meta.csv')\n",
    "test_series_meta = pd.read_csv('autodl-tmp/test_series_meta.csv')\n",
    "\n",
    "train_csv = pd.read_csv('autodl-tmp/train.csv')\n",
    "\n",
    "mid_z_csv = pd.read_csv('middle_z.csv')\n",
    "complete_series_meta = mid_z_csv[mid_z_csv.middle_z != -1].reset_index()\n",
    "complete_series_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18abfaa-5f67-428a-bf3e-91dd6b5f1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_series_meta = train_series_meta.loc[train_series_meta.patient_id.isin(train_csv.loc[train_csv.any_injury == 1, \"patient_id\"].values)]\n",
    "healthy_series_meta = train_series_meta.loc[train_series_meta.patient_id.isin(train_csv.loc[train_csv.any_injury == 0, \"patient_id\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6663e20-d085-4c93-958e-d5c13ba9b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_path_gen(patient_id, series_id, train=True):\n",
    "    if(train):\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    else:\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    \n",
    "    path += str(patient_id) + '/' + str(series_id)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def create_3D_scans(folder, downsample_rate=1): \n",
    "    filenames = os.listdir(folder)\n",
    "    filenames = [int(filename.split('.')[0]) for filename in filenames]\n",
    "    filenames = sorted(filenames)\n",
    "    filenames = [str(filename) + '.dcm' for filename in filenames]\n",
    "        \n",
    "    volume = []\n",
    "    #for filename in tqdm(filenames[::downsample_rate], position=0): \n",
    "    for filename in filenames[::downsample_rate]: \n",
    "        filepath = os.path.join(folder, filename)\n",
    "        ds = dicom.dcmread(filepath)\n",
    "        image = ds.pixel_array\n",
    "        \n",
    "        if ds.PixelRepresentation == 1:\n",
    "            bit_shift = ds.BitsAllocated - ds.BitsStored\n",
    "            dtype = image.dtype \n",
    "            image = (image << bit_shift).astype(dtype) >>  bit_shift\n",
    "        \n",
    "        # find rescale params\n",
    "        if (\"RescaleIntercept\" in ds) and (\"RescaleSlope\" in ds):\n",
    "            intercept = float(ds.RescaleIntercept)\n",
    "            slope = float(ds.RescaleSlope)\n",
    "    \n",
    "        # find clipping params\n",
    "        center = int(ds.WindowCenter)\n",
    "        width = int(ds.WindowWidth)\n",
    "        low = center - width / 2\n",
    "        high = center + width / 2    \n",
    "        \n",
    "        \n",
    "        image = (image * slope) + intercept\n",
    "        image = np.clip(image, low, high)\n",
    "\n",
    "        image = (image / np.max(image) * 255).astype(np.int16)\n",
    "        image = image[::downsample_rate, ::downsample_rate]\n",
    "        volume.append( image )\n",
    "    \n",
    "    volume = np.stack(volume, axis=0)\n",
    "    return volume\n",
    "\n",
    "def plot_image_with_seg(volume, volume_seg=[], orientation='Coronal', num_subplots=20):\n",
    "    # simply copy\n",
    "    if len(volume_seg) == 0:\n",
    "        plot_mask = 0\n",
    "    else:\n",
    "        plot_mask = 1\n",
    "        \n",
    "    if orientation == 'Coronal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([1, 0, 2])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([1, 0, 2])\n",
    "        \n",
    "    elif orientation == 'Sagittal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([2, 0, 1])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([2, 0, 1])\n",
    "\n",
    "    elif orientation == 'Axial':\n",
    "        slices = np.linspace(0, volume.shape[0]-1, num_subplots).astype(np.int16)\n",
    "           \n",
    "    rows = np.max( [np.floor(np.sqrt(num_subplots)).astype(int) - 2, 1])\n",
    "    cols = np.ceil(num_subplots/rows).astype(int)\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(cols * 2, rows * 4))\n",
    "    fig.tight_layout(h_pad=0.01, w_pad=0)\n",
    "    \n",
    "    ax = ax.ravel()\n",
    "    for this_ax in ax:\n",
    "        this_ax.axis('off')\n",
    "\n",
    "    for counter, this_slice in enumerate( slices ):\n",
    "        plt.sca(ax[counter])\n",
    "        \n",
    "        image = volume[this_slice, :, :]\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        \n",
    "        if plot_mask:\n",
    "            mask = np.where(volume_seg[this_slice, :, :], volume_seg[this_slice, :, :], np.nan)\n",
    "            plt.imshow(mask, cmap='Set1', alpha=0.5)\n",
    "            \n",
    "def load_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96459b79-cc54-4a03-8af9-f8c7af479be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = 2\n",
    "\n",
    "midz_pd = pd.read_csv('middle_z.csv')\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, root='autodl-tmp/train_images_resample/', augmentation=False, meta=train_series_meta, device='cpu'):\n",
    "        self.device = device\n",
    "        self.series_meta = meta\n",
    "        self.root = root\n",
    "        self.t = monai.transforms.Compose([monai.transforms.RandZoom(prob=0.5, min_zoom=0.9, max_zoom=1.1),\n",
    "                                           monai.transforms.RandRotate(range_x=3.14 / 24, prob=0.5),\n",
    "                                           monai.transforms.SpatialPad(spatial_size=(320//ds, 280//ds, 280//ds), mode=\"edge\"),\n",
    "                                           monai.transforms.RandSpatialCrop(roi_size=(320//ds, 256//ds, 256//ds), random_size=False),\n",
    "                                           monai.transforms.NormalizeIntensity(divisor = 400)\n",
    "                                ])\n",
    "        self.t_val = monai.transforms.Compose([monai.transforms.NormalizeIntensity(divisor = 400)])\n",
    "        \n",
    "        self.aug = augmentation\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return 1100\n",
    "        return len(self.series_meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        patient_id, series_id = self.series_meta.loc[idx, [\"patient_id\", \"series_id\"]].astype('int')\n",
    "        middle_z = midz_pd.loc[midz_pd.series_id == series_id, \"middle_z\"].values[0] // ds\n",
    "        \n",
    "        img_a = load_nii(patient_id, series_id, self.root).astype('float32')\n",
    "        #img_t = torch.from_numpy(img_a).unsqueeze(0)\n",
    "        #img_t = torch.from_numpy(img_a[::2, ::2, ::2]).unsqueeze(0)\n",
    "        if(self.aug):\n",
    "            img_t = self.t(np.expand_dims(img_a[::ds, ::ds, ::ds], 0))\n",
    "        else:\n",
    "            #img_t = torch.from_numpy(img_a[::ds, ::ds, ::ds]).unsqueeze(0)\n",
    "            img_t = self.t_val(np.expand_dims(img_a[::ds, ::ds, ::ds], 0))\n",
    "        label_columns = [\n",
    "            'kidney_healthy',\n",
    "            'kidney_low',\n",
    "            'kidney_high',\n",
    "            'liver_healthy',\n",
    "            'liver_low',\n",
    "            'liver_high',\n",
    "            'spleen_healthy',\n",
    "            'spleen_low',\n",
    "            'spleen_high',\n",
    "            #'any_injury'\n",
    "        ]\n",
    "        label_a = train_csv.loc[train_csv.patient_id == patient_id, label_columns].values[0].astype('float32')\n",
    "        label_t = torch.from_numpy(label_a)\n",
    "        label_midz = torch.tensor(middle_z.astype('int'))\n",
    "        \n",
    "        return img_t, label_t, label_midz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b82cb5-e383-44d5-9124-db85d860f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = complete_series_meta[0:3200].reset_index()\n",
    "val_meta = complete_series_meta[3200:].reset_index()\n",
    "\n",
    "# train_meta = injury_series_meta[-800:].reset_index()\n",
    "# val_meta = injury_series_meta[0:-800].reset_index()\n",
    "\n",
    "train_ds = CTDataset(meta = train_meta, augmentation=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8)\n",
    "\n",
    "val_ds = CTDataset(meta = val_meta, augmentation=False)\n",
    "val_dl = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21cf9e78-703f-4084-afdf-a4dbead38f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EffNet(nn.Module):\n",
    "#     def __init__(self, ch_out=9):\n",
    "#         super(EffNet, self).__init__()\n",
    "#         #self.conv_in = nn.Conv3d(1, 3, kernel_size=5, padding=2, stride=2)\n",
    "#         self.net = EfficientNetBN(\"efficientnet-b0\", pretrained=False, progress=False, spatial_dims=3, in_channels=1, num_classes=ch_out,)\n",
    "#     def forward(self, x):\n",
    "#         #x = self.conv_in(x)\n",
    "#         #return torch.sigmoid(self.net(x))\n",
    "#         return self.net(x)\n",
    "\n",
    "class KLSVolNet(nn.Module):\n",
    "    def __init__(self, backbone = \"tf_efficientnetv2_s.in21k_ft_in1k\", \n",
    "                 ch_in = 3, ch_out = 9, slices = 15, dropout = 0.0, pretrained=True):\n",
    "        super(KLSVolNet, self).__init__()\n",
    "        self.slices = slices\n",
    "        \n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=ch_in,\n",
    "            num_classes=ch_out,\n",
    "            features_only=False,\n",
    "            drop_rate=0.0,\n",
    "            drop_path_rate=0.0,\n",
    "            pretrained=False,\n",
    "        )\n",
    "        \n",
    "        if pretrained and 'efficient' in backbone:\n",
    "            self.encoder.load_state_dict(torch.load('pretrained/tf_efficientnetv2_s.in21k_ft_in1k_9class.pt'))\n",
    "        \n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "        \n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=0.0, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, ch_out),\n",
    "        )\n",
    "        \n",
    "        self.head2 = nn.Conv1d(slices, 1, 1)\n",
    "        \n",
    "        \n",
    "    def slicer(self, img, mid_z, slices):\n",
    "        img_kls = []\n",
    "        for i in range(0, len(mid_z)):\n",
    "            z = mid_z[i]\n",
    "            if z < 30:\n",
    "                z = 30\n",
    "            elif img.shape[-3] - z < 30:\n",
    "                z = img.shape[-3] - 31\n",
    "                \n",
    "            slice_kls = img[i, :, z-30:z+30, :, :]\n",
    "            img_kls.append(slice_kls)\n",
    "            # plot_image_with_seg(slice_kls[0].numpy(), orientation='Axial', num_subplots=7)\n",
    "        img = torch.cat(img_kls, 0)\n",
    "        img = img.unsqueeze(1)\n",
    "        #print(img.shape)\n",
    "        z_length = img.shape[-3]\n",
    "        z_slices = (np.linspace(0, z_length, slices + 2)).astype('int')\n",
    "        z_slices = z_slices[1:-1]\n",
    "        #print(z_slices)\n",
    "        slices_list = []\n",
    "        for z in z_slices:\n",
    "            slices_list.append(img[:, :, z-1:z+2, :, :])\n",
    "        img_slice = torch.cat(slices_list, 1)\n",
    "        return img_slice\n",
    "        \n",
    "    def forward(self, x, mid_z):  # (bs, nslice, ch, sz, sz)\n",
    "        x = self.slicer(x, mid_z, self.slices)\n",
    "        bs, nslice,ch, sz1, sz2 = x.shape\n",
    "        x = x.view(bs*nslice, ch, sz1, sz2)\n",
    "        \n",
    "        feature_2d = self.encoder(x)\n",
    "        feature_2d = feature_2d.view(bs, nslice, -1)\n",
    "        \n",
    "        feature_lstm, _ = self.lstm(feature_2d)\n",
    "        feature_lstm = feature_lstm.contiguous().view(bs * nslice, -1)\n",
    "        \n",
    "        preds = self.head(feature_lstm)\n",
    "        preds = preds.view(bs, nslice, -1).contiguous()\n",
    "        preds = self.head2(preds)\n",
    "        \n",
    "        return preds.squeeze(1)\n",
    "        \n",
    "        \n",
    "        # bs = x.shape[0]\n",
    "        # x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
    "        # feat = self.encoder(x)\n",
    "        # feat = feat.view(bs, n_slice_per_c, -1)\n",
    "        # feat, _ = self.lstm(feat)\n",
    "        # feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        # feat = self.head(feat)\n",
    "        # feat = feat.view(bs, n_slice_per_c).contiguous()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2396566-5acc-4bda-a87f-d2cb569dcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, labels, midz = next(iter(train_dl))\n",
    "# net = KLSVolNet(ch_out = 9)\n",
    "# img_s = net(imgs, midz)\n",
    "# img_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956083df-be19-4f19-909e-aadf9ff94280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def transform_9class(label_in):\n",
    "    label_out = [1 - label_in[0],\n",
    "                   label_in[0],\n",
    "                    1- label_in[1],\n",
    "                   label_in[1],\n",
    "                   (1 - label_in[2]) * (1 - label_in[3]),\n",
    "                   label_in[2],\n",
    "                   label_in[3],\n",
    "                   (1 - label_in[4]) * (1 - label_in[5]),\n",
    "                    label_in[4],\n",
    "                   label_in[5],\n",
    "                   (1 - label_in[6]) * (1 - label_in[7]),\n",
    "                   label_in[6],\n",
    "                   label_in[7]]\n",
    "    return label_out\n",
    "\n",
    "def transform_13class(label_in):\n",
    "    label_out = label_in\n",
    "    return label_out.tolist()\n",
    "\n",
    "def transform_kls9class(label_in):\n",
    "    label_out = [1, 1, 1, 1]\n",
    "    label_out.extend(label_in.tolist())\n",
    "    return label_out\n",
    "\n",
    "\n",
    "def loss_metrics(metrics, transform):\n",
    "    preds = [transform(x) for x in metrics[\"predict\"]]\n",
    "    targets = [transform(x) for x in metrics[\"label\"]]\n",
    "    targets_any_injury = metrics[\"label\"][:, -1]\n",
    "    \n",
    "    loss_list = []\n",
    "    \n",
    "    print(\"F1 score: \", sklearn.metrics.f1_score(metrics[\"label\"], np.around(metrics[\"predict\"]), average=None, zero_division=0.0))\n",
    "    print(\"AUC score: \", sklearn.metrics.roc_auc_score(metrics[\"label\"], metrics[\"predict\"], average=None))\n",
    "    \n",
    "    for i in range(0, len(preds)):\n",
    "        predict = preds[i]\n",
    "        target = targets[i]\n",
    "        \n",
    "        label_pred = np.zeros(14)\n",
    "        label_pred[0] = predict[0] / (predict[0] + predict[1])\n",
    "        label_pred[1] = predict[1] / (predict[0] + predict[1])\n",
    "        label_pred[2] = predict[2] / (predict[2] + predict[3])\n",
    "        label_pred[3] = predict[3] / (predict[2] + predict[3])\n",
    "        label_pred[4] = predict[4] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[5] = predict[5] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[6] = predict[6] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[7] = predict[7] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[8] = predict[8] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[9] = predict[9] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[10] = predict[10] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[11] = predict[11] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[12] = predict[12] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[13] = max([1 - label_pred[x] for x in [0, 2, 4, 7, 10]])\n",
    "        \n",
    "        targets_any_injury = max([1 - target[x] for x in [0, 2, 4, 7, 10]])\n",
    "        \n",
    "        target.append(targets_any_injury)\n",
    "        label_target = np.array(target)\n",
    "        \n",
    "        weight = np.array([1, 2, 1, 6, 1, 2, 4, 1, 2, 4, 1, 2, 4, 6])\n",
    "        \n",
    "        loss_list.append(sklearn.metrics.log_loss(\n",
    "            y_true=label_target,\n",
    "            y_pred=label_pred,\n",
    "            sample_weight=weight))\n",
    "    #print(\"Weighted Loss: \" + np.mean(loss_list))\n",
    "    \n",
    "    return np.mean(loss_list)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #print(np.array(preds).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c980ba-6bb7-46e4-9094-ad597a0c8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def TrainClassifer(model,trn_dl,val_dl,optimizer, scheduler=None,\n",
    "                   n_eopchs=20, device='cpu'):\n",
    " \n",
    "    #loss_fn = nn.BCELoss(weight=torch.Tensor([1, 6, 1, 6, 1, 4, 8, 1, 4, 8, 1, 4, 8]).to(device))\n",
    "    #loss_fn = nn.BCELoss()\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1, 30, 30, 1, 18, 18, 1, 18, 18]).to(device))\n",
    "    model.to(device)\n",
    "    best_model = copy.deepcopy(model)\n",
    "    bestweight_model = copy.deepcopy(model)\n",
    "    best_val = 999.0\n",
    "    best_weightloss = 999.0\n",
    "    metrics = {'predict': [], 'label' : []}\n",
    "    PATH_MODEL = 'KLSVol2.5D/KLSVol2.5D_Effnetv2_9class_posweight_bestloss_correct.pt'\n",
    "    PATH_MODEL2 = 'KLSVol2.5D/KLSVol2.5D_Effnetv2_9class_posweight_bestmetric_correct.pt'\n",
    "    wandb.init(name='KLSVol2.5D_Effnetv2_9class_posweight_correct', \n",
    "               project='KLSVol2.5D-test')\n",
    "\n",
    "    for epoch in range(1, n_eopchs + 1):\n",
    "        loss_train = 0.0\n",
    "        model.train()\n",
    "        for imgs, labels, midz in tqdm(trn_dl, position=0):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            midz = midz.to(device)\n",
    "\n",
    "            outputs = model(imgs, midz)\n",
    "            #outputs = model(imgs.unsqueeze(1))\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        loss_val = 0.0\n",
    "        correct_val = 0.0\n",
    "        model.eval()\n",
    "        \n",
    "        for imgs, labels, midz in tqdm(val_dl):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            midz = midz.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(imgs, midz)\n",
    "                #outputs = model(imgs.unsqueeze(1))\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss_val += loss.item()\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "                metrics['predict'].extend((outputs.to('cpu').detach().numpy()).tolist())\n",
    "                metrics['label'].extend((labels.to('cpu').detach().numpy()).tolist())\n",
    "        \n",
    "        metrics['predict'] = np.array(metrics['predict'])\n",
    "        #metrics['predict'] = np.array([[0.5, 0.5, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333]]*len(metrics['label']))\n",
    "        metrics['label'] = np.array(metrics['label'])\n",
    "        weighted_loss = loss_metrics(metrics, transform_kls9class)\n",
    "        metrics = {'predict': [], 'label' : []}\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if (weighted_loss) < best_weightloss:\n",
    "            best_weightloss = weighted_loss\n",
    "            torch.save(model.state_dict(), 'model_tmp.pt')\n",
    "            bestweight_model.load_state_dict(torch.load('model_tmp.pt'))\n",
    "            \n",
    "        if loss_val / len(val_dl) < best_val:\n",
    "            best_val = loss_val / len(val_dl)\n",
    "            torch.save(model.state_dict(), 'model_tmp.pt')\n",
    "            best_model.load_state_dict(torch.load('model_tmp.pt'))\n",
    "            \n",
    "            \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print('{} Eopch {}, Training Loss {}, Val Loss {}, Weighted Loss {}'.format(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime()),\n",
    "                                                                  epoch, loss_train / len(trn_dl), loss_val / len(val_dl),\n",
    "                                                                                     weighted_loss))\n",
    "        \n",
    "        \n",
    "        \n",
    "        wandb.log({'training loss': loss_train / len(trn_dl),\n",
    "                  'val loss': loss_val / len(val_dl),\n",
    "                  'weighted loss': weighted_loss})\n",
    "    torch.save(best_model.state_dict(), PATH_MODEL)\n",
    "    torch.save(bestweight_model.state_dict(), PATH_MODEL2)\n",
    "    print('Finish training: best_val:{}, best_weighted loss:{}'.format(best_val, best_weightloss))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6bea54d-c0bc-4f01-80a2-953649b113a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnorthm\u001b[0m (\u001b[33mrsna2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c821fdffac47be8758d32a8c1ea683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669557119409244, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20230925_001628-4erqrg59</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rsna2023/KLSVol2.5D-test/runs/4erqrg59' target=\"_blank\">KLSVol2.5D_Effnetv2_9class_posweight_correct</a></strong> to <a href='https://wandb.ai/rsna2023/KLSVol2.5D-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rsna2023/KLSVol2.5D-test' target=\"_blank\">https://wandb.ai/rsna2023/KLSVol2.5D-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rsna2023/KLSVol2.5D-test/runs/4erqrg59' target=\"_blank\">https://wandb.ai/rsna2023/KLSVol2.5D-test/runs/4erqrg59</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:08<00:00,  3.21it/s]\n",
      "100%|██████████| 300/300 [01:11<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.96584522 0.07184241 0.01351351 0.95179667 0.12807882 0.06779661\n",
      " 0.91405184 0.1363212  0.11730205]\n",
      "AUC score:  [0.43870617 0.54042465 0.40841419 0.55405905 0.54560283 0.59787596\n",
      " 0.5741072  0.58844002 0.57609777]\n",
      "2023-09-25 00:21:59 Eopch 1, Training Loss 1.0555245834589004, Val Loss 0.9879976946115494, Weighted Loss 0.5799525404904532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:09<00:00,  3.21it/s]\n",
      "100%|██████████| 300/300 [01:10<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.96629213 0.07978723 0.02205882 0.95179667 0.15338645 0.09090909\n",
      " 0.92349235 0.14537902 0.15212528]\n",
      "AUC score:  [0.49267464 0.59132138 0.49177839 0.61075727 0.62762589 0.71197961\n",
      " 0.62269541 0.64298344 0.68151201]\n",
      "2023-09-25 00:27:22 Eopch 2, Training Loss 0.9610975135490298, Val Loss 0.9283594818909963, Weighted Loss 0.5463494254689262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:13<00:00,  3.15it/s]\n",
      "100%|██████████| 300/300 [01:13<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.96807593 0.08414239 0.03125    0.95271454 0.17767107 0.08247423\n",
      " 0.92735426 0.15922799 0.1694291 ]\n",
      "AUC score:  [0.51596901 0.5955267  0.54825568 0.6533887  0.68279639 0.74957519\n",
      " 0.66485548 0.68369517 0.73950547]\n",
      "2023-09-25 00:32:53 Eopch 3, Training Loss 0.9036338406801224, Val Loss 0.8924297892550628, Weighted Loss 0.528966304385655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:32<00:00,  2.94it/s]\n",
      "100%|██████████| 300/300 [01:19<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97076526 0.08446456 0.0391198  0.95412844 0.18424242 0.07317073\n",
      " 0.93166592 0.16981132 0.17785844]\n",
      "AUC score:  [0.53407176 0.62661307 0.59417821 0.68073052 0.70352544 0.79218352\n",
      " 0.67916694 0.692547   0.75954242]\n",
      "2023-09-25 00:38:47 Eopch 4, Training Loss 0.8604971330612898, Val Loss 0.8700724659363429, Weighted Loss 0.5243372744958273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:31<00:00,  2.94it/s]\n",
      "100%|██████████| 300/300 [01:18<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97164948 0.0952381  0.05949657 0.95412844 0.18963338 0.07665505\n",
      " 0.93357111 0.17100372 0.17935702]\n",
      "AUC score:  [0.56125306 0.64137291 0.6042145  0.70469421 0.70655243 0.7664401\n",
      " 0.70241639 0.69808639 0.78148359]\n",
      "2023-09-25 00:44:40 Eopch 5, Training Loss 0.8163613367080689, Val Loss 0.8654464973012607, Weighted Loss 0.5250236367297262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:07<00:00,  3.23it/s]\n",
      "100%|██████████| 300/300 [01:13<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97164948 0.10588235 0.05394191 0.95458515 0.18905473 0.08360129\n",
      " 0.93214286 0.17295981 0.17320261]\n",
      "AUC score:  [0.61077739 0.6729128  0.62699059 0.72032691 0.71145125 0.78708581\n",
      " 0.72223483 0.70480081 0.79199943]\n",
      "2023-09-25 00:50:03 Eopch 6, Training Loss 0.7737991939485073, Val Loss 0.856479490151008, Weighted Loss 0.525993246782245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:11<00:00,  3.18it/s]\n",
      "100%|██████████| 300/300 [01:13<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97209103 0.10071942 0.0913242  0.95458515 0.22932331 0.07272727\n",
      " 0.93594306 0.19646365 0.24324324]\n",
      "AUC score:  [0.61475945 0.6527314  0.67535738 0.71984306 0.72960253 0.79617672\n",
      " 0.71678126 0.70248433 0.80740372]\n",
      "2023-09-25 00:55:31 Eopch 7, Training Loss 0.7306166055426001, Val Loss 0.8374218788991372, Weighted Loss 0.47853163328854365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:12<00:00,  3.16it/s]\n",
      "100%|██████████| 300/300 [01:16<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97164948 0.0995671  0.08695652 0.95458515 0.22259136 0.09248555\n",
      " 0.93273543 0.18902439 0.23873874]\n",
      "AUC score:  [0.65330253 0.66617192 0.69824457 0.75057182 0.73980661 0.81920136\n",
      " 0.77446098 0.70718442 0.84442234]\n",
      "2023-09-25 01:01:02 Eopch 8, Training Loss 0.6920528915897012, Val Loss 0.8070778169731299, Weighted Loss 0.4895451176075856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:28<00:00,  2.97it/s]\n",
      "100%|██████████| 300/300 [01:15<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97209103 0.09647495 0.08333333 0.95458515 0.21568627 0.08490566\n",
      " 0.93512304 0.20068027 0.27891156]\n",
      "AUC score:  [0.64199511 0.65341167 0.68287534 0.75011436 0.74171052 0.81236194\n",
      " 0.78407983 0.72946509 0.84298707]\n",
      "2023-09-25 01:06:48 Eopch 9, Training Loss 0.6558404370397329, Val Loss 0.8148213771979014, Weighted Loss 0.48321483268725873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:20<00:00,  3.08it/s]\n",
      "100%|██████████| 300/300 [01:14<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97164948 0.10778443 0.08866995 0.95458515 0.22621185 0.10447761\n",
      " 0.93837157 0.20863309 0.29461756]\n",
      "AUC score:  [0.65691764 0.64271284 0.71172506 0.74561018 0.74667351 0.81338148\n",
      " 0.78767773 0.72448523 0.8687651 ]\n",
      "2023-09-25 01:12:25 Eopch 10, Training Loss 0.6144657106883824, Val Loss 0.8086900131156047, Weighted Loss 0.46980982682113925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:13<00:00,  3.15it/s]\n",
      "100%|██████████| 300/300 [01:10<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97164948 0.11253197 0.09       0.95408833 0.23352166 0.11688312\n",
      " 0.93520616 0.19748654 0.2923588 ]\n",
      "AUC score:  [0.69387062 0.69954649 0.7262425  0.74487121 0.74178539 0.81397621\n",
      " 0.78695347 0.70020143 0.84990763]\n",
      "2023-09-25 01:17:52 Eopch 11, Training Loss 0.5684572496451438, Val Loss 0.815493677308162, Weighted Loss 0.4656494727486025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:10<00:00,  3.20it/s]\n",
      "100%|██████████| 300/300 [01:12<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97120756 0.08783784 0.08648649 0.95367133 0.20155039 0.13333333\n",
      " 0.93181818 0.19607843 0.28235294]\n",
      "AUC score:  [0.6824069  0.64745413 0.73205688 0.72957281 0.71877808 0.81639762\n",
      " 0.78774448 0.70442032 0.85169817]\n",
      "2023-09-25 01:23:17 Eopch 12, Training Loss 0.5399895875155926, Val Loss 0.8485135273138682, Weighted Loss 0.4606202538384809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:11<00:00,  3.18it/s]\n",
      "100%|██████████| 300/300 [01:11<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97164948 0.10795455 0.11494253 0.95346795 0.2303263  0.12244898\n",
      " 0.93747147 0.18487395 0.33333333]\n",
      "AUC score:  [0.70789617 0.66365698 0.72913118 0.76539517 0.74577504 0.82327952\n",
      " 0.77001535 0.69864593 0.84399602]\n",
      "2023-09-25 01:28:42 Eopch 13, Training Loss 0.5073269617650658, Val Loss 0.8388949419682225, Weighted Loss 0.4584512172980417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:12<00:00,  3.17it/s]\n",
      "100%|██████████| 300/300 [01:12<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.96854804 0.11825193 0.0896861  0.94223018 0.20666667 0.12745098\n",
      " 0.93944954 0.19312602 0.35964912]\n",
      "AUC score:  [0.69937483 0.67831375 0.72072439 0.75307024 0.7351859  0.85463042\n",
      " 0.79323143 0.72110564 0.85810715]\n",
      "2023-09-25 01:34:09 Eopch 14, Training Loss 0.4607989541534334, Val Loss 0.8353529335434238, Weighted Loss 0.469082796910015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:11<00:00,  3.18it/s]\n",
      "100%|██████████| 300/300 [01:10<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.96933045 0.09975062 0.13533835 0.95017794 0.24524313 0.1656051\n",
      " 0.92827004 0.2045929  0.28346457]\n",
      "AUC score:  [0.72054906 0.67746856 0.72446485 0.78715075 0.75119796 0.85471538\n",
      " 0.79619518 0.70994852 0.8628677 ]\n",
      "2023-09-25 01:39:32 Eopch 15, Training Loss 0.44830383692868053, Val Loss 0.8596634702757001, Weighted Loss 0.4588731293845137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:10<00:00,  3.20it/s]\n",
      "100%|██████████| 300/300 [01:15<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.9707401  0.13559322 0.12307692 0.95090668 0.21866667 0.15217391\n",
      " 0.93913043 0.20654912 0.40540541]\n",
      "AUC score:  [0.67916553 0.64108431 0.72568699 0.75728412 0.72108844 0.84966015\n",
      " 0.80359122 0.70779991 0.88152622]\n",
      "2023-09-25 01:45:00 Eopch 16, Training Loss 0.4021144661493599, Val Loss 0.9467691573438545, Weighted Loss 0.4301966162742329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:14<00:00,  3.14it/s]\n",
      "100%|██████████| 300/300 [01:09<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.96799308 0.1218638  0.10958904 0.93089245 0.22222222 0.15584416\n",
      " 0.93758669 0.21052632 0.376     ]\n",
      "AUC score:  [0.70907855 0.64417646 0.70931783 0.77418362 0.73613785 0.85726423\n",
      " 0.80658835 0.71459266 0.86855194]\n",
      "2023-09-25 01:50:25 Eopch 17, Training Loss 0.3776387169025838, Val Loss 0.8967878385509054, Weighted Loss 0.4562663545396144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:18<00:00,  3.10it/s]\n",
      "100%|██████████| 300/300 [01:11<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.97068966 0.07843137 0.15929204 0.95013357 0.23834197 0.14583333\n",
      " 0.93603313 0.23376623 0.4       ]\n",
      "AUC score:  [0.68068089 0.62059369 0.72816828 0.77718348 0.73894023 0.87693288\n",
      " 0.79587477 0.71796106 0.87015774]\n",
      "2023-09-25 01:55:58 Eopch 18, Training Loss 0.34521014263853433, Val Loss 0.9768688413066169, Weighted Loss 0.4275878951545166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:17<00:00,  3.11it/s]\n",
      "100%|██████████| 300/300 [01:15<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.96893874 0.12322275 0.09876543 0.92969473 0.21501706 0.19047619\n",
      " 0.93302326 0.20967742 0.38427948]\n",
      "AUC score:  [0.70737972 0.644094   0.71420636 0.78183722 0.73289693 0.87795242\n",
      " 0.79179628 0.69942927 0.8684951 ]\n",
      "2023-09-25 02:01:32 Eopch 19, Training Loss 0.32860485489480196, Val Loss 0.9675145973016819, Weighted Loss 0.4448542137280309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:14<00:00,  3.14it/s]\n",
      "100%|██████████| 300/300 [01:11<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.9667099  0.09187279 0.10526316 0.93437357 0.21308411 0.1443299\n",
      " 0.93097015 0.19892473 0.375     ]\n",
      "AUC score:  [0.71986953 0.62189239 0.7160951  0.77574952 0.72010439 0.87056075\n",
      " 0.78152994 0.68899955 0.87115248]\n",
      "2023-09-25 02:07:00 Eopch 20, Training Loss 0.297320228475146, Val Loss 0.9863317882021269, Weighted Loss 0.44630982719001994\n",
      "Finish training: best_val:0.8070778169731299, best_weighted loss:0.4275878951545166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec899bb52827496bbb96d81c393bcbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>█▇▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>val loss</td><td>█▆▄▃▃▃▂▁▁▁▁▃▂▂▃▆▄█▇█</td></tr><tr><td>weighted loss</td><td>█▆▆▅▅▆▃▄▄▃▃▃▂▃▂▁▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>0.29732</td></tr><tr><td>val loss</td><td>0.98633</td></tr><tr><td>weighted loss</td><td>0.44631</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">KLSVol2.5D_Effnetv2_9class_posweight_correct</strong> at: <a href='https://wandb.ai/rsna2023/KLSVol2.5D-test/runs/4erqrg59' target=\"_blank\">https://wandb.ai/rsna2023/KLSVol2.5D-test/runs/4erqrg59</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230925_001628-4erqrg59/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = KLSVolNet(ch_out = 9).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-5)\n",
    "TrainClassifer(model=net,trn_dl=train_dl,val_dl=val_dl,optimizer=optimizer, \n",
    "               scheduler=None, n_eopchs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80efa8c-d2f4-4b23-aaf4-e8cd70587d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
