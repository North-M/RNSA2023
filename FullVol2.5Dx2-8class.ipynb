{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf32a2a-7118-4d81-b093-818e344d05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import pydicom as dicom\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import monai\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monai.networks.nets import EfficientNetBN\n",
    "from monai.networks.nets import ResNet\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "import timm\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a795ca56-6bcd-4967-b375-dc59214d526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish seeding with seed 344\n",
      "Training on device cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 344\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # Fix the network according to random seed\n",
    "    print('Finish seeding with seed {}'.format(seed))\n",
    "    \n",
    "seed_everything(SEED)\n",
    "print('Training on device {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a8a495-8bee-478e-a16b-0e27bfd70da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "      <th>any_injury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>9951</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>9960</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>9961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>9980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>9983</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3147 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0          10004              1             0                      0   \n",
       "1          10005              1             0                      1   \n",
       "2          10007              1             0                      1   \n",
       "3          10026              1             0                      1   \n",
       "4          10051              1             0                      1   \n",
       "...          ...            ...           ...                    ...   \n",
       "3142        9951              1             0                      1   \n",
       "3143        9960              1             0                      1   \n",
       "3144        9961              1             0                      1   \n",
       "3145        9980              1             0                      1   \n",
       "3146        9983              1             0                      1   \n",
       "\n",
       "      extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0                        1               0           1            0   \n",
       "1                        0               1           0            0   \n",
       "2                        0               1           0            0   \n",
       "3                        0               1           0            0   \n",
       "4                        0               1           0            0   \n",
       "...                    ...             ...         ...          ...   \n",
       "3142                     0               1           0            0   \n",
       "3143                     0               1           0            0   \n",
       "3144                     0               1           0            0   \n",
       "3145                     0               1           0            0   \n",
       "3146                     0               1           0            0   \n",
       "\n",
       "      liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0                 1          0           0               0           0   \n",
       "1                 1          0           0               1           0   \n",
       "2                 1          0           0               1           0   \n",
       "3                 1          0           0               1           0   \n",
       "4                 1          0           0               0           1   \n",
       "...             ...        ...         ...             ...         ...   \n",
       "3142              1          0           0               1           0   \n",
       "3143              1          0           0               1           0   \n",
       "3144              1          0           0               1           0   \n",
       "3145              1          0           0               0           0   \n",
       "3146              1          0           0               0           0   \n",
       "\n",
       "      spleen_high  any_injury  \n",
       "0               1           1  \n",
       "1               0           0  \n",
       "2               0           0  \n",
       "3               0           0  \n",
       "4               0           1  \n",
       "...           ...         ...  \n",
       "3142            0           0  \n",
       "3143            0           0  \n",
       "3144            0           0  \n",
       "3145            1           1  \n",
       "3146            1           1  \n",
       "\n",
       "[3147 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicom_tag_columns = [\n",
    "    'Columns',\n",
    "    'ImageOrientationPatient',\n",
    "    'ImagePositionPatient',\n",
    "    'InstanceNumber',\n",
    "    'PatientID',\n",
    "    'PatientPosition',\n",
    "    'PixelSpacing',\n",
    "    'RescaleIntercept',\n",
    "    'RescaleSlope',\n",
    "    'Rows',\n",
    "    'SeriesNumber',\n",
    "    'SliceThickness',\n",
    "    'path',\n",
    "    'WindowCenter',\n",
    "    'WindowWidth'\n",
    "]\n",
    "\n",
    "train_dicom_tags = pd.read_parquet('autodl-tmp/train_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "test_dicom_tags = pd.read_parquet('autodl-tmp/test_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "\n",
    "train_series_meta = pd.read_csv('autodl-tmp/train_series_meta.csv')\n",
    "test_series_meta = pd.read_csv('autodl-tmp/test_series_meta.csv')\n",
    "\n",
    "train_csv = pd.read_csv('autodl-tmp/train.csv')\n",
    "\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b75b036-35cc-4f07-9480-1d2ff2ab6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_series_meta = train_series_meta.loc[train_series_meta.patient_id.isin(train_csv.loc[train_csv.any_injury == 1, \"patient_id\"].values)]\n",
    "healthy_series_meta = train_series_meta.loc[train_series_meta.patient_id.isin(train_csv.loc[train_csv.any_injury == 0, \"patient_id\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7096cd30-8868-4b07-b313-ea7cfce8fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_path_gen(patient_id, series_id, train=True):\n",
    "    if(train):\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    else:\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    \n",
    "    path += str(patient_id) + '/' + str(series_id)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def create_3D_scans(folder, downsample_rate=1): \n",
    "    filenames = os.listdir(folder)\n",
    "    filenames = [int(filename.split('.')[0]) for filename in filenames]\n",
    "    filenames = sorted(filenames)\n",
    "    filenames = [str(filename) + '.dcm' for filename in filenames]\n",
    "        \n",
    "    volume = []\n",
    "    #for filename in tqdm(filenames[::downsample_rate], position=0): \n",
    "    for filename in filenames[::downsample_rate]: \n",
    "        filepath = os.path.join(folder, filename)\n",
    "        ds = dicom.dcmread(filepath)\n",
    "        image = ds.pixel_array\n",
    "        \n",
    "        if ds.PixelRepresentation == 1:\n",
    "            bit_shift = ds.BitsAllocated - ds.BitsStored\n",
    "            dtype = image.dtype \n",
    "            image = (image << bit_shift).astype(dtype) >>  bit_shift\n",
    "        \n",
    "        # find rescale params\n",
    "        if (\"RescaleIntercept\" in ds) and (\"RescaleSlope\" in ds):\n",
    "            intercept = float(ds.RescaleIntercept)\n",
    "            slope = float(ds.RescaleSlope)\n",
    "    \n",
    "        # find clipping params\n",
    "        center = int(ds.WindowCenter)\n",
    "        width = int(ds.WindowWidth)\n",
    "        low = center - width / 2\n",
    "        high = center + width / 2    \n",
    "        \n",
    "        \n",
    "        image = (image * slope) + intercept\n",
    "        image = np.clip(image, low, high)\n",
    "\n",
    "        image = (image / np.max(image) * 255).astype(np.int16)\n",
    "        image = image[::downsample_rate, ::downsample_rate]\n",
    "        volume.append( image )\n",
    "    \n",
    "    volume = np.stack(volume, axis=0)\n",
    "    return volume\n",
    "\n",
    "def plot_image_with_seg(volume, volume_seg=[], orientation='Coronal', num_subplots=20):\n",
    "    # simply copy\n",
    "    if len(volume_seg) == 0:\n",
    "        plot_mask = 0\n",
    "    else:\n",
    "        plot_mask = 1\n",
    "        \n",
    "    if orientation == 'Coronal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([1, 0, 2])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([1, 0, 2])\n",
    "        \n",
    "    elif orientation == 'Sagittal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([2, 0, 1])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([2, 0, 1])\n",
    "\n",
    "    elif orientation == 'Axial':\n",
    "        slices = np.linspace(0, volume.shape[0]-1, num_subplots).astype(np.int16)\n",
    "           \n",
    "    rows = np.max( [np.floor(np.sqrt(num_subplots)).astype(int) - 2, 1])\n",
    "    cols = np.ceil(num_subplots/rows).astype(int)\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(cols * 2, rows * 4))\n",
    "    fig.tight_layout(h_pad=0.01, w_pad=0)\n",
    "    \n",
    "    ax = ax.ravel()\n",
    "    for this_ax in ax:\n",
    "        this_ax.axis('off')\n",
    "\n",
    "    for counter, this_slice in enumerate( slices ):\n",
    "        plt.sca(ax[counter])\n",
    "        \n",
    "        image = volume[this_slice, :, :]\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        \n",
    "        if plot_mask:\n",
    "            mask = np.where(volume_seg[this_slice, :, :], volume_seg[this_slice, :, :], np.nan)\n",
    "            plt.imshow(mask, cmap='Set1', alpha=0.5)\n",
    "            \n",
    "def load_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2141f4ef-37c8-4cef-b89d-7ff9a539c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = 2\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, root='autodl-tmp/train_images_resample/', augmentation=False, meta=train_series_meta, device='cpu'):\n",
    "        self.device = device\n",
    "        self.series_meta = meta\n",
    "        self.root = root\n",
    "        self.t = monai.transforms.Compose([monai.transforms.RandZoom(prob=0.5, min_zoom=0.9, max_zoom=1.1),\n",
    "                                           monai.transforms.RandRotate(range_x=3.14 / 24, prob=0.5),\n",
    "                                           monai.transforms.SpatialPad(spatial_size=(320//ds, 280, 280), mode=\"edge\"),\n",
    "                                           monai.transforms.RandSpatialCrop(roi_size=(320//ds, 256, 256), random_size=False),\n",
    "                                           monai.transforms.NormalizeIntensity(divisor = 400)\n",
    "                                ])\n",
    "        self.t_val = monai.transforms.Compose([monai.transforms.NormalizeIntensity(divisor = 400)])\n",
    "        \n",
    "        self.aug = augmentation\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return 1100\n",
    "        return len(self.series_meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        patient_id, series_id = self.series_meta.loc[idx, [\"patient_id\", \"series_id\"]].astype('int')\n",
    "        img_a = load_nii(patient_id, series_id, self.root).astype('float32')\n",
    "        #img_t = torch.from_numpy(img_a).unsqueeze(0)\n",
    "        #img_t = torch.from_numpy(img_a[::2, ::2, ::2]).unsqueeze(0)\n",
    "        if(self.aug):\n",
    "            img_t = self.t(np.expand_dims(img_a[::ds, :, :], 0))\n",
    "        else:\n",
    "            #img_t = torch.from_numpy(img_a[::ds, ::ds, ::ds]).unsqueeze(0)\n",
    "            img_t = self.t_val(np.expand_dims(img_a[::ds, :, :], 0))\n",
    "        label_columns = [\n",
    "            'bowel_injury',\n",
    "            'extravasation_injury',\n",
    "            'kidney_low',\n",
    "            'kidney_high',\n",
    "            'liver_low',\n",
    "            'liver_high',\n",
    "            'spleen_low',\n",
    "            'spleen_high',\n",
    "            #'any_injury'\n",
    "        ]\n",
    "        label_a = train_csv.loc[train_csv.patient_id == patient_id, label_columns].values[0].astype('float32')\n",
    "        label_t = torch.from_numpy(label_a)\n",
    "        return img_t, label_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd90d76-a251-4d2d-9667-6b4c23550672",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = train_series_meta[-3600:].reset_index()\n",
    "val_meta = train_series_meta[0:-3600].reset_index()\n",
    "\n",
    "# train_meta = injury_series_meta[-800:].reset_index()\n",
    "# val_meta = injury_series_meta[0:-800].reset_index()\n",
    "\n",
    "train_ds = CTDataset(meta = train_meta, augmentation=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8)\n",
    "\n",
    "val_ds = CTDataset(meta = val_meta, augmentation=False)\n",
    "val_dl = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1f0a1d-e6aa-4575-b1f1-5efd4457a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EffNet(nn.Module):\n",
    "#     def __init__(self, ch_out=9):\n",
    "#         super(EffNet, self).__init__()\n",
    "#         #self.conv_in = nn.Conv3d(1, 3, kernel_size=5, padding=2, stride=2)\n",
    "#         self.net = EfficientNetBN(\"efficientnet-b0\", pretrained=False, progress=False, spatial_dims=3, in_channels=1, num_classes=ch_out,)\n",
    "#     def forward(self, x):\n",
    "#         #x = self.conv_in(x)\n",
    "#         #return torch.sigmoid(self.net(x))\n",
    "#         return self.net(x)\n",
    "\n",
    "class FullVolNet(nn.Module):\n",
    "    def __init__(self, backbone = \"tf_efficientnetv2_s.in21k_ft_in1k\", \n",
    "                 ch_in = 3, ch_out = 9, slices = 15, dropout = 0.0, pretrained=True):\n",
    "        super(FullVolNet, self).__init__()\n",
    "        self.slices = slices\n",
    "        \n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=ch_in,\n",
    "            num_classes=ch_out,\n",
    "            features_only=False,\n",
    "            drop_rate=0.0,\n",
    "            drop_path_rate=0.0,\n",
    "            pretrained=False,\n",
    "        )\n",
    "        \n",
    "        if 'efficient' in backbone and pretrained:\n",
    "            self.encoder.load_state_dict(torch.load('pretrained/tf_efficientnetv2_s.in21k_ft_in1k_8class.pt'))\n",
    "        elif 'convnext' in backbone and pretrained:\n",
    "            self.encoder.load_state_dict(torch.load('pretrained/convnextv2_nano.fcmae_ft_in22k_in1k_384_8class.pt'))\n",
    "        \n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "        \n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=0.0, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, ch_out),\n",
    "        )\n",
    "        \n",
    "        self.head2 = nn.Conv1d(slices, 1, 1)\n",
    "        \n",
    "        \n",
    "    def slicer(self, img, slices):\n",
    "        #img = img.squeeze(1)\n",
    "        z_length = img.shape[-3]\n",
    "        z_slices = (np.linspace(0, z_length, slices + 4)).astype('int')\n",
    "        z_slices = z_slices[2:-2]\n",
    "        #print(z_slices)\n",
    "        slices_list = []\n",
    "        for z in z_slices:\n",
    "            slices_list.append(img[:, :, z-1:z+2, :, :])\n",
    "        img_slice = torch.cat(slices_list, 1)\n",
    "        return img_slice\n",
    "        \n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        x = self.slicer(x, self.slices)\n",
    "        bs, nslice,ch, sz1, sz2 = x.shape\n",
    "        x = x.view(bs*nslice, ch, sz1, sz2)\n",
    "        \n",
    "        feature_2d = self.encoder(x)\n",
    "        feature_2d = feature_2d.view(bs, nslice, -1)\n",
    "        \n",
    "        feature_lstm, _ = self.lstm(feature_2d)\n",
    "        feature_lstm = feature_lstm.contiguous().view(bs * nslice, -1)\n",
    "        \n",
    "        preds = self.head(feature_lstm)\n",
    "        preds = preds.view(bs, nslice, -1).contiguous()\n",
    "        preds = self.head2(preds)\n",
    "        \n",
    "        return preds.squeeze(1)\n",
    "        \n",
    "        \n",
    "        # bs = x.shape[0]\n",
    "        # x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
    "        # feat = self.encoder(x)\n",
    "        # feat = feat.view(bs, n_slice_per_c, -1)\n",
    "        # feat, _ = self.lstm(feat)\n",
    "        # feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        # feat = self.head(feat)\n",
    "        # feat = feat.view(bs, n_slice_per_c).contiguous()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452b48a5-36e6-4c16-967c-5b5e151c5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avail_pretrained_models = timm.list_models(pretrained=True)\n",
    "# avail_pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b95491b-07eb-45ea-90f6-456377057226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, labels = next(iter(train_dl))\n",
    "# net = FullVolNet(ch_out = 8)\n",
    "# img_s = net(imgs)\n",
    "# img_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70166a4-8e5a-464a-8c95-6186f62f56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_a = imgs[0, 0].numpy()\n",
    "# print(img_a.shape)\n",
    "# plot_image_with_seg(img_a, orientation='Axial', num_subplots=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af7441f-f99e-44ef-8e67-11273ff4ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def transform_9class(label_in):\n",
    "    label_out = [1 - label_in[0],\n",
    "                   label_in[0],\n",
    "                    1- label_in[1],\n",
    "                   label_in[1],\n",
    "                   (1 - label_in[2]) * (1 - label_in[3]),\n",
    "                   label_in[2],\n",
    "                   label_in[3],\n",
    "                   (1 - label_in[4]) * (1 - label_in[5]),\n",
    "                    label_in[4],\n",
    "                   label_in[5],\n",
    "                   (1 - label_in[6]) * (1 - label_in[7]),\n",
    "                   label_in[6],\n",
    "                   label_in[7]]\n",
    "    return label_out\n",
    "\n",
    "def transform_13class(label_in):\n",
    "    label_out = label_in\n",
    "    return label_out.tolist()\n",
    "\n",
    "\n",
    "def loss_metrics(metrics, transform):\n",
    "    preds = [transform(x) for x in metrics[\"predict\"]]\n",
    "    targets = [transform(x) for x in metrics[\"label\"]]\n",
    "    targets_any_injury = metrics[\"label\"][:, -1]\n",
    "    \n",
    "    loss_list = []\n",
    "    \n",
    "    print(\"F1 score: \", sklearn.metrics.f1_score(metrics[\"label\"], np.around(metrics[\"predict\"]), average=None, zero_division=0.0))\n",
    "    print(\"AUC score: \", sklearn.metrics.roc_auc_score(metrics[\"label\"], metrics[\"predict\"], average=None))\n",
    "    \n",
    "    for i in range(0, len(preds)):\n",
    "        predict = preds[i]\n",
    "        target = targets[i]\n",
    "        \n",
    "        label_pred = np.zeros(14)\n",
    "        label_pred[0] = predict[0] / (predict[0] + predict[1])\n",
    "        label_pred[1] = predict[1] / (predict[0] + predict[1])\n",
    "        label_pred[2] = predict[2] / (predict[2] + predict[3])\n",
    "        label_pred[3] = predict[3] / (predict[2] + predict[3])\n",
    "        label_pred[4] = predict[4] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[5] = predict[5] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[6] = predict[6] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[7] = predict[7] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[8] = predict[8] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[9] = predict[9] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[10] = predict[10] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[11] = predict[11] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[12] = predict[12] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[13] = max([1 - label_pred[x] for x in [0, 2, 4, 7, 10]])\n",
    "        \n",
    "        targets_any_injury = max([1 - target[x] for x in [0, 2, 4, 7, 10]])\n",
    "        \n",
    "        target.append(targets_any_injury)\n",
    "        label_target = np.array(target)\n",
    "        \n",
    "        weight = np.array([1, 2, 1, 6, 1, 2, 4, 1, 2, 4, 1, 2, 4, 6])\n",
    "        \n",
    "        loss_list.append(sklearn.metrics.log_loss(\n",
    "            y_true=label_target,\n",
    "            y_pred=label_pred,\n",
    "            sample_weight=weight))\n",
    "    #print(\"Weighted Loss: \" + np.mean(loss_list))\n",
    "    \n",
    "    return np.mean(loss_list)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #print(np.array(preds).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc4c8d8-bcaf-457a-a88e-48e6d3bdb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "def TrainClassifer(model,trn_dl,val_dl,optimizer, scheduler=None,\n",
    "                   n_eopchs=20, device='cpu'):\n",
    " \n",
    "    #loss_fn = nn.BCELoss(weight=torch.Tensor([1, 6, 1, 6, 1, 4, 8, 1, 4, 8, 1, 4, 8]).to(device))\n",
    "    #loss_fn = nn.BCELoss()\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([10, 5, 10, 10, 6, 6, 6, 6]).to(device))\n",
    "    model.to(device)\n",
    "    best_model = copy.deepcopy(model)\n",
    "    bestweight_model = copy.deepcopy(model)\n",
    "    best_val = 999.0\n",
    "    best_weightloss = 999.0\n",
    "    metrics = {'predict': [], 'label' : []}\n",
    "    PATH_MODEL = 'FullVol2.5D/FullVol2.5Dx2_Effnetv2_15s_8class_posweight_bestloss.pt'\n",
    "    PATH_MODEL2 = 'FullVol2.5D/FullVol2.5Dx2_Effnetv2_15s_8class_posweight_bestmetric.pt'\n",
    "    wandb.init(name='FullVol2.5Dx2_Effnetv2_15s_8class_posweight', \n",
    "               project='FullVol2.5Dx2-test')\n",
    "\n",
    "    for epoch in range(1, n_eopchs + 1):\n",
    "        loss_train = 0.0\n",
    "        model.train()\n",
    "        for imgs, labels in tqdm(trn_dl, position=0):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # outputs = model(imgs)\n",
    "            # #outputs = model(imgs.unsqueeze(1))\n",
    "            # loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            with amp.autocast():\n",
    "                outputs = model(imgs)\n",
    "                #outputs = model(imgs.unsqueeze(1))\n",
    "                loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        loss_val = 0.0\n",
    "        correct_val = 0.0\n",
    "        model.eval()\n",
    "        \n",
    "        for imgs, labels in tqdm(val_dl):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(imgs)\n",
    "                #outputs = model(imgs.unsqueeze(1))\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss_val += loss.item()\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "                metrics['predict'].extend((outputs.to('cpu').detach().numpy()).tolist())\n",
    "                metrics['label'].extend((labels.to('cpu').detach().numpy()).tolist())\n",
    "        \n",
    "        metrics['predict'] = np.array(metrics['predict'])\n",
    "        #metrics['predict'] = np.array([[0.5, 0.5, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333]]*len(metrics['label']))\n",
    "        metrics['label'] = np.array(metrics['label'])\n",
    "        weighted_loss = loss_metrics(metrics, transform_9class)\n",
    "        metrics = {'predict': [], 'label' : []}\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if (weighted_loss) < best_weightloss:\n",
    "            best_weightloss = weighted_loss\n",
    "            torch.save(model.state_dict(), 'model_tmp.pt')\n",
    "            bestweight_model.load_state_dict(torch.load('model_tmp.pt'))\n",
    "            \n",
    "        if loss_val / len(val_dl) < best_val:\n",
    "            best_val = loss_val / len(val_dl)\n",
    "            torch.save(model.state_dict(), 'model_tmp.pt')\n",
    "            best_model.load_state_dict(torch.load('model_tmp.pt'))\n",
    "            \n",
    "            \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print('{} Eopch {}, Training Loss {}, Val Loss {}, Weighted Loss {}'.format(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime()),\n",
    "                                                                  epoch, loss_train / len(trn_dl), loss_val / len(val_dl),\n",
    "                                                                                     weighted_loss))\n",
    "        \n",
    "        \n",
    "        \n",
    "        wandb.log({'training loss': loss_train / len(trn_dl),\n",
    "                  'val loss': loss_val / len(val_dl),\n",
    "                  'weighted loss': weighted_loss})\n",
    "    torch.save(best_model.state_dict(), PATH_MODEL)\n",
    "    torch.save(bestweight_model.state_dict(), PATH_MODEL2)\n",
    "    print('Finish training: best_val:{}, best_weighted loss:{}'.format(best_val, best_weightloss))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "732ea298-acdd-451a-8881-b6f393a121e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnorthm\u001b[0m (\u001b[33mrsna2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20230927_093112-7nx70ywr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/7nx70ywr' target=\"_blank\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</a></strong> to <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/7nx70ywr' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/7nx70ywr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [25:32<00:00,  1.70s/it]\n",
      "100%|██████████| 278/278 [03:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.         0.         0.         0.         0.11382114 0.\n",
      " 0.         0.        ]\n",
      "AUC score:  [0.65029639 0.60995856 0.52504704 0.62570042 0.65571879 0.56502964\n",
      " 0.57084898 0.72934473]\n",
      "2023-09-27 10:00:16 Eopch 1, Training Loss 0.721630132926835, Val Loss 0.7088304307820986, Weighted Loss 0.44807930293970505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [25:31<00:00,  1.70s/it]\n",
      "100%|██████████| 278/278 [02:55<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.13953488 0.07619048 0.1372549  0.05263158 0.21576763 0.\n",
      " 0.13846154 0.10958904]\n",
      "AUC score:  [0.6736567  0.59829229 0.6023244  0.7263906  0.67429535 0.69701702\n",
      " 0.63237817 0.7723745 ]\n",
      "2023-09-27 10:28:46 Eopch 2, Training Loss 0.6320073745813635, Val Loss 0.6897507039227074, Weighted Loss 0.45096606137667244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [25:35<00:00,  1.71s/it]\n",
      "100%|██████████| 278/278 [02:58<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.16981132 0.13978495 0.14035088 0.19047619 0.23684211 0.06666667\n",
      " 0.256      0.24203822]\n",
      "AUC score:  [0.71779591 0.61373294 0.63769991 0.83569086 0.70334095 0.76305054\n",
      " 0.66024482 0.77062252]\n",
      "2023-09-27 10:57:22 Eopch 3, Training Loss 0.5927680295374659, Val Loss 0.6685555429606558, Weighted Loss 0.444844828358237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [25:34<00:00,  1.71s/it]\n",
      "100%|██████████| 278/278 [03:15<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.18181818 0.14173228 0.13445378 0.16326531 0.30555556 0.0952381\n",
      " 0.18666667 0.19642857]\n",
      "AUC score:  [0.74459813 0.6830971  0.6974365  0.87330873 0.72864294 0.78316018\n",
      " 0.69041823 0.81109801]\n",
      "2023-09-27 11:26:15 Eopch 4, Training Loss 0.553960018803676, Val Loss 0.6316895273467191, Weighted Loss 0.3533614532659339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [25:34<00:00,  1.70s/it]\n",
      "100%|██████████| 278/278 [03:16<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.16216216 0.13157895 0.11851852 0.24561404 0.29333333 0.17021277\n",
      " 0.17085427 0.32      ]\n",
      "AUC score:  [0.75549748 0.69961992 0.72544293 0.84126008 0.71148112 0.76910574\n",
      " 0.68733482 0.84191309]\n",
      "2023-09-27 11:55:09 Eopch 5, Training Loss 0.51391793164942, Val Loss 0.6255136293848212, Weighted Loss 0.35306154555472374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [25:31<00:00,  1.70s/it]\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 900/900 [25:28<00:00,  1.70s/it]\n",
      "100%|██████████| 278/278 [03:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.12765957 0.25555556 0.24761905 0.21052632 0.2893617  0.21052632\n",
      " 0.21390374 0.43589744]\n",
      "AUC score:  [0.81843967 0.72125003 0.74653104 0.82506492 0.68564588 0.79915865\n",
      " 0.69670098 0.83567476]\n",
      "2023-09-27 16:14:53 Eopch 14, Training Loss 0.24268061221887668, Val Loss 0.7024006092344686, Weighted Loss 0.28853014826742535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [25:28<00:00,  1.70s/it]\n",
      "100%|██████████| 278/278 [03:26<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.19047619 0.24691358 0.31081081 0.21333333 0.26865672 0.20338983\n",
      " 0.2        0.47297297]\n",
      "AUC score:  [0.79453757 0.7402935  0.78498354 0.81320897 0.68671237 0.79782013\n",
      " 0.68260537 0.88468088]\n",
      "2023-09-27 16:43:50 Eopch 15, Training Loss 0.2164276312581367, Val Loss 0.6899892746088959, Weighted Loss 0.2912379918383983\n",
      "Finish training: best_val:0.617762660956104, best_weighted loss:0.28853014826742535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e903f1ea88124c7a9428b3c2614cdf36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>█▇▆▆▅▅▄▄▃▃▃▂▂▁▁</td></tr><tr><td>val loss</td><td>█▇▅▂▂▁▁▂▂▄▂▃▄█▇</td></tr><tr><td>weighted loss</td><td>███▄▄▃▃▃▂▂▂▁▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>0.21643</td></tr><tr><td>val loss</td><td>0.68999</td></tr><tr><td>weighted loss</td><td>0.29124</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</strong> at: <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/7nx70ywr' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/7nx70ywr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230927_093112-7nx70ywr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#net = FullVolNet(backbone = 'convnextv2_nano.fcmae_ft_in22k_in1k_384', ch_out = 8, slices=15).to(device)\n",
    "net = FullVolNet(ch_out = 8, slices=15).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-5)\n",
    "TrainClassifer(model=net,trn_dl=train_dl,val_dl=val_dl,optimizer=optimizer, \n",
    "               scheduler=None, n_eopchs=15, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea3821-71ab-4773-84c4-cacfabba3cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
