{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf32a2a-7118-4d81-b093-818e344d05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import pydicom as dicom\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import monai\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monai.networks.nets import EfficientNetBN\n",
    "from monai.networks.nets import ResNet\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "import timm\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a795ca56-6bcd-4967-b375-dc59214d526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish seeding with seed 344\n",
      "Training on device cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 344\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # Fix the network according to random seed\n",
    "    print('Finish seeding with seed {}'.format(seed))\n",
    "    \n",
    "seed_everything(SEED)\n",
    "print('Training on device {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a8a495-8bee-478e-a16b-0e27bfd70da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "      <th>any_injury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>9951</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>9960</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>9961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>9980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>9983</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3147 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0          10004              1             0                      0   \n",
       "1          10005              1             0                      1   \n",
       "2          10007              1             0                      1   \n",
       "3          10026              1             0                      1   \n",
       "4          10051              1             0                      1   \n",
       "...          ...            ...           ...                    ...   \n",
       "3142        9951              1             0                      1   \n",
       "3143        9960              1             0                      1   \n",
       "3144        9961              1             0                      1   \n",
       "3145        9980              1             0                      1   \n",
       "3146        9983              1             0                      1   \n",
       "\n",
       "      extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0                        1               0           1            0   \n",
       "1                        0               1           0            0   \n",
       "2                        0               1           0            0   \n",
       "3                        0               1           0            0   \n",
       "4                        0               1           0            0   \n",
       "...                    ...             ...         ...          ...   \n",
       "3142                     0               1           0            0   \n",
       "3143                     0               1           0            0   \n",
       "3144                     0               1           0            0   \n",
       "3145                     0               1           0            0   \n",
       "3146                     0               1           0            0   \n",
       "\n",
       "      liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0                 1          0           0               0           0   \n",
       "1                 1          0           0               1           0   \n",
       "2                 1          0           0               1           0   \n",
       "3                 1          0           0               1           0   \n",
       "4                 1          0           0               0           1   \n",
       "...             ...        ...         ...             ...         ...   \n",
       "3142              1          0           0               1           0   \n",
       "3143              1          0           0               1           0   \n",
       "3144              1          0           0               1           0   \n",
       "3145              1          0           0               0           0   \n",
       "3146              1          0           0               0           0   \n",
       "\n",
       "      spleen_high  any_injury  \n",
       "0               1           1  \n",
       "1               0           0  \n",
       "2               0           0  \n",
       "3               0           0  \n",
       "4               0           1  \n",
       "...           ...         ...  \n",
       "3142            0           0  \n",
       "3143            0           0  \n",
       "3144            0           0  \n",
       "3145            1           1  \n",
       "3146            1           1  \n",
       "\n",
       "[3147 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicom_tag_columns = [\n",
    "    'Columns',\n",
    "    'ImageOrientationPatient',\n",
    "    'ImagePositionPatient',\n",
    "    'InstanceNumber',\n",
    "    'PatientID',\n",
    "    'PatientPosition',\n",
    "    'PixelSpacing',\n",
    "    'RescaleIntercept',\n",
    "    'RescaleSlope',\n",
    "    'Rows',\n",
    "    'SeriesNumber',\n",
    "    'SliceThickness',\n",
    "    'path',\n",
    "    'WindowCenter',\n",
    "    'WindowWidth'\n",
    "]\n",
    "\n",
    "train_dicom_tags = pd.read_parquet('autodl-tmp/train_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "test_dicom_tags = pd.read_parquet('autodl-tmp/test_dicom_tags.parquet', columns=dicom_tag_columns)\n",
    "\n",
    "train_series_meta = pd.read_csv('autodl-tmp/train_series_meta.csv')\n",
    "test_series_meta = pd.read_csv('autodl-tmp/test_series_meta.csv')\n",
    "\n",
    "train_csv = pd.read_csv('autodl-tmp/train.csv')\n",
    "\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b75b036-35cc-4f07-9480-1d2ff2ab6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_series_meta = train_series_meta.loc[train_series_meta.patient_id.isin(train_csv.loc[train_csv.any_injury == 1, \"patient_id\"].values)]\n",
    "healthy_series_meta = train_series_meta.loc[train_series_meta.patient_id.isin(train_csv.loc[train_csv.any_injury == 0, \"patient_id\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7096cd30-8868-4b07-b313-ea7cfce8fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_path_gen(patient_id, series_id, train=True):\n",
    "    if(train):\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    else:\n",
    "        path = 'autodl-tmp/train_images_resample/'\n",
    "    \n",
    "    path += str(patient_id) + '/' + str(series_id)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def create_3D_scans(folder, downsample_rate=1): \n",
    "    filenames = os.listdir(folder)\n",
    "    filenames = [int(filename.split('.')[0]) for filename in filenames]\n",
    "    filenames = sorted(filenames)\n",
    "    filenames = [str(filename) + '.dcm' for filename in filenames]\n",
    "        \n",
    "    volume = []\n",
    "    #for filename in tqdm(filenames[::downsample_rate], position=0): \n",
    "    for filename in filenames[::downsample_rate]: \n",
    "        filepath = os.path.join(folder, filename)\n",
    "        ds = dicom.dcmread(filepath)\n",
    "        image = ds.pixel_array\n",
    "        \n",
    "        if ds.PixelRepresentation == 1:\n",
    "            bit_shift = ds.BitsAllocated - ds.BitsStored\n",
    "            dtype = image.dtype \n",
    "            image = (image << bit_shift).astype(dtype) >>  bit_shift\n",
    "        \n",
    "        # find rescale params\n",
    "        if (\"RescaleIntercept\" in ds) and (\"RescaleSlope\" in ds):\n",
    "            intercept = float(ds.RescaleIntercept)\n",
    "            slope = float(ds.RescaleSlope)\n",
    "    \n",
    "        # find clipping params\n",
    "        center = int(ds.WindowCenter)\n",
    "        width = int(ds.WindowWidth)\n",
    "        low = center - width / 2\n",
    "        high = center + width / 2    \n",
    "        \n",
    "        \n",
    "        image = (image * slope) + intercept\n",
    "        image = np.clip(image, low, high)\n",
    "\n",
    "        image = (image / np.max(image) * 255).astype(np.int16)\n",
    "        image = image[::downsample_rate, ::downsample_rate]\n",
    "        volume.append( image )\n",
    "    \n",
    "    volume = np.stack(volume, axis=0)\n",
    "    return volume\n",
    "\n",
    "def plot_image_with_seg(volume, volume_seg=[], orientation='Coronal', num_subplots=20):\n",
    "    # simply copy\n",
    "    if len(volume_seg) == 0:\n",
    "        plot_mask = 0\n",
    "    else:\n",
    "        plot_mask = 1\n",
    "        \n",
    "    if orientation == 'Coronal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([1, 0, 2])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([1, 0, 2])\n",
    "        \n",
    "    elif orientation == 'Sagittal':\n",
    "        slices = np.linspace(0, volume.shape[2]-1, num_subplots).astype(np.int16)\n",
    "        volume = volume.transpose([2, 0, 1])\n",
    "        if plot_mask:\n",
    "            volume_seg = volume_seg.transpose([2, 0, 1])\n",
    "\n",
    "    elif orientation == 'Axial':\n",
    "        slices = np.linspace(0, volume.shape[0]-1, num_subplots).astype(np.int16)\n",
    "           \n",
    "    rows = np.max( [np.floor(np.sqrt(num_subplots)).astype(int) - 2, 1])\n",
    "    cols = np.ceil(num_subplots/rows).astype(int)\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(cols * 2, rows * 4))\n",
    "    fig.tight_layout(h_pad=0.01, w_pad=0)\n",
    "    \n",
    "    ax = ax.ravel()\n",
    "    for this_ax in ax:\n",
    "        this_ax.axis('off')\n",
    "\n",
    "    for counter, this_slice in enumerate( slices ):\n",
    "        plt.sca(ax[counter])\n",
    "        \n",
    "        image = volume[this_slice, :, :]\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        \n",
    "        if plot_mask:\n",
    "            mask = np.where(volume_seg[this_slice, :, :], volume_seg[this_slice, :, :], np.nan)\n",
    "            plt.imshow(mask, cmap='Set1', alpha=0.5)\n",
    "            \n",
    "def load_nii(patient_id, series_id, root='autodl-tmp/train_images_resample/'):\n",
    "    path = root + str(patient_id) + '/' + str(series_id) + '.nii.gz'\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # img = nib.load(path)\n",
    "    # img = img.get_fdata().transpose(2, 1, 0)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2141f4ef-37c8-4cef-b89d-7ff9a539c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = 2\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, root='autodl-tmp/train_images_resample/', augmentation=False, meta=train_series_meta, device='cpu'):\n",
    "        self.device = device\n",
    "        self.series_meta = meta\n",
    "        self.root = root\n",
    "        self.t = monai.transforms.Compose([monai.transforms.RandZoom(prob=0.5, min_zoom=0.9, max_zoom=1.1),\n",
    "                                           monai.transforms.RandRotate(range_x=3.14 / 24, prob=0.5),\n",
    "                                           monai.transforms.SpatialPad(spatial_size=(320//ds, 280, 280), mode=\"edge\"),\n",
    "                                           monai.transforms.RandSpatialCrop(roi_size=(320//ds, 256, 256), random_size=False),\n",
    "                                           monai.transforms.NormalizeIntensity(divisor = 400)\n",
    "                                ])\n",
    "        self.t_val = monai.transforms.Compose([monai.transforms.NormalizeIntensity(divisor = 400)])\n",
    "        \n",
    "        self.aug = augmentation\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return 1100\n",
    "        return len(self.series_meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        patient_id, series_id = self.series_meta.loc[idx, [\"patient_id\", \"series_id\"]].astype('int')\n",
    "        img_a = load_nii(patient_id, series_id, self.root).astype('float32')\n",
    "        #img_t = torch.from_numpy(img_a).unsqueeze(0)\n",
    "        #img_t = torch.from_numpy(img_a[::2, ::2, ::2]).unsqueeze(0)\n",
    "        if(self.aug):\n",
    "            img_t = self.t(np.expand_dims(img_a[::ds, :, :], 0))\n",
    "        else:\n",
    "            #img_t = torch.from_numpy(img_a[::ds, ::ds, ::ds]).unsqueeze(0)\n",
    "            img_t = self.t_val(np.expand_dims(img_a[::ds, :, :], 0))\n",
    "        label_columns = [\n",
    "            'bowel_injury',\n",
    "            'extravasation_injury',\n",
    "            'kidney_low',\n",
    "            'kidney_high',\n",
    "            'liver_low',\n",
    "            'liver_high',\n",
    "            'spleen_low',\n",
    "            'spleen_high',\n",
    "            #'any_injury'\n",
    "        ]\n",
    "        label_a = train_csv.loc[train_csv.patient_id == patient_id, label_columns].values[0].astype('float32')\n",
    "        label_t = torch.from_numpy(label_a)\n",
    "        return img_t, label_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd90d76-a251-4d2d-9667-6b4c23550672",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = train_series_meta[-3600:].reset_index()\n",
    "val_meta = train_series_meta[0:-3600].reset_index()\n",
    "\n",
    "# train_meta = injury_series_meta[-800:].reset_index()\n",
    "# val_meta = injury_series_meta[0:-800].reset_index()\n",
    "\n",
    "train_ds = CTDataset(meta = train_meta, augmentation=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8)\n",
    "\n",
    "val_ds = CTDataset(meta = val_meta, augmentation=False)\n",
    "val_dl = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1f0a1d-e6aa-4575-b1f1-5efd4457a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EffNet(nn.Module):\n",
    "#     def __init__(self, ch_out=9):\n",
    "#         super(EffNet, self).__init__()\n",
    "#         #self.conv_in = nn.Conv3d(1, 3, kernel_size=5, padding=2, stride=2)\n",
    "#         self.net = EfficientNetBN(\"efficientnet-b0\", pretrained=False, progress=False, spatial_dims=3, in_channels=1, num_classes=ch_out,)\n",
    "#     def forward(self, x):\n",
    "#         #x = self.conv_in(x)\n",
    "#         #return torch.sigmoid(self.net(x))\n",
    "#         return self.net(x)\n",
    "\n",
    "class FullVolNet(nn.Module):\n",
    "    def __init__(self, backbone = \"tf_efficientnetv2_s.in21k_ft_in1k\", \n",
    "                 ch_in = 3, ch_out = 9, slices = 15, dropout = 0.0, pretrained=True):\n",
    "        super(FullVolNet, self).__init__()\n",
    "        self.slices = slices\n",
    "        \n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=ch_in,\n",
    "            num_classes=ch_out,\n",
    "            features_only=False,\n",
    "            drop_rate=0.0,\n",
    "            drop_path_rate=0.0,\n",
    "            pretrained=False,\n",
    "        )\n",
    "        \n",
    "        if 'efficient' in backbone and pretrained:\n",
    "            self.encoder.load_state_dict(torch.load('pretrained/tf_efficientnetv2_s.in21k_ft_in1k_8class.pt'))\n",
    "        elif 'convnext' in backbone and pretrained:\n",
    "            self.encoder.load_state_dict(torch.load('pretrained/convnextv2_nano.fcmae_ft_in22k_in1k_384_8class.pt'))\n",
    "        \n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "        \n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=0.0, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, ch_out),\n",
    "        )\n",
    "        \n",
    "        self.head2 = nn.Conv1d(slices, 1, 1)\n",
    "        \n",
    "        \n",
    "    def slicer(self, img, slices):\n",
    "        #img = img.squeeze(1)\n",
    "        z_length = img.shape[-3]\n",
    "        z_slices = (np.linspace(0, z_length, slices + 4)).astype('int')\n",
    "        z_slices = z_slices[2:-2]\n",
    "        #print(z_slices)\n",
    "        slices_list = []\n",
    "        for z in z_slices:\n",
    "            slices_list.append(img[:, :, z-1:z+2, :, :])\n",
    "        img_slice = torch.cat(slices_list, 1)\n",
    "        return img_slice\n",
    "        \n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        x = self.slicer(x, self.slices)\n",
    "        bs, nslice,ch, sz1, sz2 = x.shape\n",
    "        x = x.view(bs*nslice, ch, sz1, sz2)\n",
    "        \n",
    "        feature_2d = self.encoder(x)\n",
    "        feature_2d = feature_2d.view(bs, nslice, -1)\n",
    "        \n",
    "        feature_lstm, _ = self.lstm(feature_2d)\n",
    "        feature_lstm = feature_lstm.contiguous().view(bs * nslice, -1)\n",
    "        \n",
    "        preds = self.head(feature_lstm)\n",
    "        preds = preds.view(bs, nslice, -1).contiguous()\n",
    "        preds = self.head2(preds)\n",
    "        \n",
    "        return preds.squeeze(1)\n",
    "        \n",
    "        \n",
    "        # bs = x.shape[0]\n",
    "        # x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
    "        # feat = self.encoder(x)\n",
    "        # feat = feat.view(bs, n_slice_per_c, -1)\n",
    "        # feat, _ = self.lstm(feat)\n",
    "        # feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        # feat = self.head(feat)\n",
    "        # feat = feat.view(bs, n_slice_per_c).contiguous()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452b48a5-36e6-4c16-967c-5b5e151c5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avail_pretrained_models = timm.list_models(pretrained=True)\n",
    "# avail_pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b95491b-07eb-45ea-90f6-456377057226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, labels = next(iter(train_dl))\n",
    "# net = FullVolNet(ch_out = 8)\n",
    "# img_s = net(imgs)\n",
    "# img_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70166a4-8e5a-464a-8c95-6186f62f56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_a = imgs[0, 0].numpy()\n",
    "# print(img_a.shape)\n",
    "# plot_image_with_seg(img_a, orientation='Axial', num_subplots=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af7441f-f99e-44ef-8e67-11273ff4ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def transform_9class(label_in):\n",
    "    label_out = [1 - label_in[0],\n",
    "                   label_in[0],\n",
    "                    1- label_in[1],\n",
    "                   label_in[1],\n",
    "                   (1 - label_in[2]) * (1 - label_in[3]),\n",
    "                   label_in[2],\n",
    "                   label_in[3],\n",
    "                   (1 - label_in[4]) * (1 - label_in[5]),\n",
    "                    label_in[4],\n",
    "                   label_in[5],\n",
    "                   (1 - label_in[6]) * (1 - label_in[7]),\n",
    "                   label_in[6],\n",
    "                   label_in[7]]\n",
    "    return label_out\n",
    "\n",
    "def transform_13class(label_in):\n",
    "    label_out = label_in\n",
    "    return label_out.tolist()\n",
    "\n",
    "\n",
    "def loss_metrics(metrics, transform):\n",
    "    preds = [transform(x) for x in metrics[\"predict\"]]\n",
    "    targets = [transform(x) for x in metrics[\"label\"]]\n",
    "    targets_any_injury = metrics[\"label\"][:, -1]\n",
    "    \n",
    "    loss_list = []\n",
    "    \n",
    "    print(\"F1 score: \", sklearn.metrics.f1_score(metrics[\"label\"], np.around(metrics[\"predict\"]), average=None, zero_division=0.0))\n",
    "    print(\"AUC score: \", sklearn.metrics.roc_auc_score(metrics[\"label\"], metrics[\"predict\"], average=None))\n",
    "    \n",
    "    for i in range(0, len(preds)):\n",
    "        predict = preds[i]\n",
    "        target = targets[i]\n",
    "        \n",
    "        label_pred = np.zeros(14)\n",
    "        label_pred[0] = predict[0] / (predict[0] + predict[1])\n",
    "        label_pred[1] = predict[1] / (predict[0] + predict[1])\n",
    "        label_pred[2] = predict[2] / (predict[2] + predict[3])\n",
    "        label_pred[3] = predict[3] / (predict[2] + predict[3])\n",
    "        label_pred[4] = predict[4] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[5] = predict[5] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[6] = predict[6] / (predict[4] + predict[5] + predict[6])\n",
    "        label_pred[7] = predict[7] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[8] = predict[8] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[9] = predict[9] / (predict[7] + predict[8] + predict[9])\n",
    "        label_pred[10] = predict[10] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[11] = predict[11] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[12] = predict[12] / (predict[10] + predict[11] + predict[12])\n",
    "        label_pred[13] = max([1 - label_pred[x] for x in [0, 2, 4, 7, 10]])\n",
    "        \n",
    "        targets_any_injury = max([1 - target[x] for x in [0, 2, 4, 7, 10]])\n",
    "        \n",
    "        target.append(targets_any_injury)\n",
    "        label_target = np.array(target)\n",
    "        \n",
    "        weight = np.array([1, 2, 1, 6, 1, 2, 4, 1, 2, 4, 1, 2, 4, 6])\n",
    "        \n",
    "        loss_list.append(sklearn.metrics.log_loss(\n",
    "            y_true=label_target,\n",
    "            y_pred=label_pred,\n",
    "            sample_weight=weight))\n",
    "    #print(\"Weighted Loss: \" + np.mean(loss_list))\n",
    "    \n",
    "    return np.mean(loss_list)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #print(np.array(preds).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc4c8d8-bcaf-457a-a88e-48e6d3bdb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "def TrainClassifer(model,trn_dl,val_dl,optimizer, project, name, suffix, scheduler=None,\n",
    "                   n_eopchs=20, device='cpu'):\n",
    " \n",
    "    #loss_fn = nn.BCELoss(weight=torch.Tensor([1, 6, 1, 6, 1, 4, 8, 1, 4, 8, 1, 4, 8]).to(device))\n",
    "    #loss_fn = nn.BCELoss()\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([10, 5, 10, 10, 6, 6, 6, 6]).to(device))\n",
    "    model.to(device)\n",
    "    best_model = copy.deepcopy(model)\n",
    "    bestweight_model = copy.deepcopy(model)\n",
    "    best_val = 999.0\n",
    "    best_weightloss = 999.0\n",
    "    metrics = {'predict': [], 'label' : []}\n",
    "    PATH_MODEL = project + '/' + name + '/' + suffix + '.pt'\n",
    "    wandb.init(name=name, \n",
    "               project=project)\n",
    "\n",
    "    for epoch in range(1, n_eopchs + 1):\n",
    "        loss_train = 0.0\n",
    "        model.train()\n",
    "        for imgs, labels in tqdm(trn_dl, position=0):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # outputs = model(imgs)\n",
    "            # #outputs = model(imgs.unsqueeze(1))\n",
    "            # loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            with amp.autocast():\n",
    "                outputs = model(imgs)\n",
    "                #outputs = model(imgs.unsqueeze(1))\n",
    "                loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        loss_val = 0.0\n",
    "        correct_val = 0.0\n",
    "        model.eval()\n",
    "        \n",
    "        for imgs, labels in tqdm(val_dl):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(imgs)\n",
    "                #outputs = model(imgs.unsqueeze(1))\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss_val += loss.item()\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "                metrics['predict'].extend((outputs.to('cpu').detach().numpy()).tolist())\n",
    "                metrics['label'].extend((labels.to('cpu').detach().numpy()).tolist())\n",
    "        \n",
    "        metrics['predict'] = np.array(metrics['predict'])\n",
    "        #metrics['predict'] = np.array([[0.5, 0.5, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333, 0.33333]]*len(metrics['label']))\n",
    "        metrics['label'] = np.array(metrics['label'])\n",
    "        weighted_loss = loss_metrics(metrics, transform_9class)\n",
    "        metrics = {'predict': [], 'label' : []}\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if (weighted_loss) < best_weightloss:\n",
    "            best_weightloss = weighted_loss\n",
    "            \n",
    "        if loss_val / len(val_dl) < best_val:\n",
    "            best_val = loss_val / len(val_dl)\n",
    "            torch.save(model.state_dict(), 'model_tmp.pt')\n",
    "            best_model.load_state_dict(torch.load('model_tmp.pt'))\n",
    "            \n",
    "            \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print('{} Eopch {}, Training Loss {}, Val Loss {}, Weighted Loss {}'.format(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime()),\n",
    "                                                                  epoch, loss_train / len(trn_dl), loss_val / len(val_dl),\n",
    "                                                                                     weighted_loss))\n",
    "        \n",
    "        \n",
    "        \n",
    "        wandb.log({'training loss': loss_train / len(trn_dl),\n",
    "                  'val loss': loss_val / len(val_dl),\n",
    "                  'weighted loss': weighted_loss})\n",
    "    torch.save(best_model.state_dict(), PATH_MODEL)\n",
    "    print('Finish training: best_val:{}, best_weighted loss:{}'.format(best_val, best_weightloss))\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82a090d8-7dd6-4c6f-a4ba-05ff4008c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project = \"FullVol2.5Dx2-nophase-4fold\"\n",
    "name = \"FullVol2.5Dx2-nophase_Convnetv2_4fold\"\n",
    "# backbone = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "backbone = 'convnextv2_nano.fcmae_ft_in22k_in1k_384'\n",
    "n_eopchs = 12\n",
    "\n",
    "p = project + '/' + name\n",
    "if not os.path.exists(p):\n",
    "    os.mkdir(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7483d3db-f739-4d7e-b3bf-6048f5cfde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4711 // 4 = 1178\n",
    "\n",
    "train_df_fold1 = train_series_meta[1178:].reset_index(drop=True)\n",
    "train_df_fold2 = pd.concat([train_series_meta[0:1178], train_series_meta[2356:]], axis=0).reset_index(drop=True)\n",
    "train_df_fold3 = pd.concat([train_series_meta[0:2356], train_series_meta[3534:]], axis=0).reset_index(drop=True)\n",
    "train_df_fold4 = train_series_meta[:3534].reset_index()\n",
    "\n",
    "val_df_fold1 = train_series_meta[0:1178].reset_index(drop=True)\n",
    "val_df_fold2 = train_series_meta[1178:2356].reset_index(drop=True)\n",
    "val_df_fold3 = train_series_meta[2356:3534].reset_index(drop=True)\n",
    "val_df_fold4 = train_series_meta[3534:].reset_index(drop=True)\n",
    "\n",
    "train_ds_fold1 = CTDataset(meta = train_df_fold1, augmentation=True)\n",
    "train_dl_fold1 = DataLoader(train_ds_fold1, batch_size=4, shuffle=True, num_workers=8)\n",
    "val_ds_fold1 = CTDataset(meta = val_df_fold1, augmentation=False)\n",
    "val_dl_fold1 = DataLoader(val_ds_fold1, batch_size=4, shuffle=False, num_workers=8)\n",
    "\n",
    "train_ds_fold2 = CTDataset(meta = train_df_fold2, augmentation=True)\n",
    "train_dl_fold2 = DataLoader(train_ds_fold2, batch_size=4, shuffle=True, num_workers=8)\n",
    "val_ds_fold2 = CTDataset(meta = val_df_fold2, augmentation=False)\n",
    "val_dl_fold2 = DataLoader(val_ds_fold2, batch_size=4, shuffle=False, num_workers=8)\n",
    "\n",
    "train_ds_fold3 = CTDataset(meta = train_df_fold3, augmentation=True)\n",
    "train_dl_fold3 = DataLoader(train_ds_fold3, batch_size=4, shuffle=True, num_workers=8)\n",
    "val_ds_fold3 = CTDataset(meta = val_df_fold3, augmentation=False)\n",
    "val_dl_fold3 = DataLoader(val_ds_fold3, batch_size=4, shuffle=False, num_workers=8)\n",
    "\n",
    "train_ds_fold4 = CTDataset(meta = train_df_fold4, augmentation=True)\n",
    "train_dl_fold4 = DataLoader(train_ds_fold4, batch_size=4, shuffle=True, num_workers=8)\n",
    "val_ds_fold4 = CTDataset(meta = val_df_fold4, augmentation=False)\n",
    "val_dl_fold4 = DataLoader(val_ds_fold4, batch_size=4, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aba6db4d-617d-4d7e-8f3c-e84955b3a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnorthm\u001b[0m (\u001b[33mrsna2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705bd05607c747d6b411591802fc99a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669607938577732, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20231001_115754-8vyedb4m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/8vyedb4m' target=\"_blank\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</a></strong> to <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/8vyedb4m' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/8vyedb4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:55<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:18<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.09756098 0.         0.03389831 0.         0.15767635 0.\n",
      " 0.         0.        ]\n",
      "AUC score:  [0.61894901 0.59243663 0.56446919 0.6528882  0.63544202 0.6637856\n",
      " 0.54508369 0.75931723]\n",
      "2023-10-01 12:30:13 Eopch 1, Training Loss 0.6875071620138792, Val Loss 0.6894081056623136, Weighted Loss 0.39113226187961003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:47<00:00,  1.95s/it]\n",
      "100%|██████████| 295/295 [03:16<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.         0.02469136 0.10309278 0.         0.22413793 0.\n",
      " 0.16149068 0.19117647]\n",
      "AUC score:  [0.70550104 0.67343737 0.62347029 0.75618012 0.66075214 0.77344618\n",
      " 0.63825413 0.79752534]\n",
      "2023-10-01 13:02:19 Eopch 2, Training Loss 0.6213568830483369, Val Loss 0.6552936989372059, Weighted Loss 0.3833374996501636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:54<00:00,  1.96s/it]\n",
      " 64%|██████▍   | 190/295 [01:58<01:45,  1.00s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 884/884 [28:52<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.12605042 0.23364486 0.12200436 0.15942029 0.2181146  0.1682243\n",
      " 0.22545455 0.32098765]\n",
      "AUC score:  [0.76912458 0.74027154 0.70137922 0.76754658 0.69438447 0.84925422\n",
      " 0.67137398 0.85201252]\n",
      "2023-10-01 14:06:08 Eopch 4, Training Loss 0.5234435155515758, Val Loss 0.6607550944185863, Weighted Loss 0.4897854752585575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:51<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:06<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.22222222 0.18181818 0.20155039 0.12       0.22916667 0.11111111\n",
      " 0.13636364 0.33333333]\n",
      "AUC score:  [0.79802527 0.74279581 0.70680212 0.76568323 0.7003219  0.84175145\n",
      " 0.67592702 0.88176804]\n",
      "2023-10-01 14:38:07 Eopch 5, Training Loss 0.48556525600711686, Val Loss 0.6273895484537392, Weighted Loss 0.3019396390058965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 736/884 [24:05<04:49,  1.95s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 295/295 [03:20<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.0952381  0.22222222 0.09756098 0.11363636 0.16949153 0.22222222\n",
      " 0.17073171 0.37681159]\n",
      "AUC score:  [0.82953693 0.7354943  0.75857269 0.63468944 0.66207702 0.83781999\n",
      " 0.67295625 0.86079308]\n",
      "2023-10-01 18:23:50 Eopch 12, Training Loss 0.19635835481698022, Val Loss 0.82998504038837, Weighted Loss 0.2799061618244913\n",
      "Finish training: best_val:0.6273895484537392, best_weighted loss:0.2752880620599474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>█▇▆▆▅▄▄▃▃▂▂▁</td></tr><tr><td>val loss</td><td>▃▂▁▂▁▂▂▃▄▄▄█</td></tr><tr><td>weighted loss</td><td>▅▅▅█▂▁▆▂▂▁▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>0.19636</td></tr><tr><td>val loss</td><td>0.82999</td></tr><tr><td>weighted loss</td><td>0.27991</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</strong> at: <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/8vyedb4m' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/8vyedb4m</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231001_115754-8vyedb4m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff0adfc129f4d3ea0d398e0aa5b281a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668826807290316, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20231001_182400-rcdenm2k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/rcdenm2k' target=\"_blank\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</a></strong> to <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/rcdenm2k' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/rcdenm2k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:57<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:55<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "AUC score:  [0.83890317 0.57422587 0.52912057 0.65942009 0.72120945 0.67341079\n",
      " 0.64289265 0.66251514]\n",
      "2023-10-01 18:56:58 Eopch 1, Training Loss 0.70589496569531, Val Loss 0.6425037007210619, Weighted Loss 0.38949963138183225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:59<00:00,  1.56s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 884/884 [29:04<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:42<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.13333333 0.1443299  0.11891892 0.06315789 0.27439024 0.09090909\n",
      " 0.18937644 0.18978102]\n",
      "AUC score:  [0.87847628 0.70007969 0.65155523 0.82259471 0.7518685  0.85950855\n",
      " 0.68680898 0.80094358]\n",
      "2023-10-01 20:02:43 Eopch 3, Training Loss 0.6129875259128361, Val Loss 0.605844645833565, Weighted Loss 0.4488674892161398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 385/884 [12:47<16:20,  1.96s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 884/884 [29:06<00:00,  1.98s/it]\n",
      "100%|██████████| 295/295 [04:02<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.10447761 0.21656051 0.13636364 0.21052632 0.3286119  0.22222222\n",
      " 0.22222222 0.33175355]\n",
      "AUC score:  [0.90963621 0.70299408 0.74094116 0.87813933 0.78249078 0.86411592\n",
      " 0.73724089 0.88743877]\n",
      "2023-10-01 22:47:46 Eopch 8, Training Loss 0.41741179917597665, Val Loss 0.5490297484448401, Weighted Loss 0.36793966694702956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [29:05<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [04:01<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.21052632 0.14864865 0.15686275 0.17721519 0.30452675 0.32142857\n",
      " 0.224      0.37398374]\n",
      "AUC score:  [0.88509776 0.70217441 0.72418631 0.86143375 0.77860209 0.88304621\n",
      " 0.73877238 0.89889915]\n",
      "2023-10-01 23:20:55 Eopch 9, Training Loss 0.3830842376008158, Val Loss 0.5448693524351564, Weighted Loss 0.2878853287837735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:58<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:57<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.07692308 0.1884058  0.20382166 0.16666667 0.31690141 0.38297872\n",
      " 0.2278481  0.50847458]\n",
      "AUC score:  [0.87652878 0.6801571  0.7539883  0.86835222 0.76908722 0.87059295\n",
      " 0.76666174 0.9056597 ]\n",
      "2023-10-01 23:53:52 Eopch 10, Training Loss 0.3456476076223732, Val Loss 0.5564768998299615, Weighted Loss 0.28158065368187274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [29:01<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [04:04<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.0952381  0.23963134 0.21818182 0.26530612 0.25498008 0.36065574\n",
      " 0.19103314 0.29304029]\n",
      "AUC score:  [0.90356002 0.71762295 0.72977794 0.86283995 0.74258345 0.84588675\n",
      " 0.75483966 0.91204064]\n",
      "2023-10-02 00:27:00 Eopch 11, Training Loss 0.30889497285632933, Val Loss 0.5908101556159682, Weighted Loss 0.3668286871660854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:54<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:24<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.08333333 0.19512195 0.18421053 0.20408163 0.23469388 0.34615385\n",
      " 0.21857923 0.46296296]\n",
      "AUC score:  [0.88190387 0.66870446 0.72699214 0.83415361 0.76278073 0.86394899\n",
      " 0.75560541 0.88704109]\n",
      "2023-10-02 00:59:20 Eopch 12, Training Loss 0.27261656022112296, Val Loss 0.6233540039572676, Weighted Loss 0.2420850278730046\n",
      "Finish training: best_val:0.5448693524351564, best_weighted loss:0.2420850278730046\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b61b94903c943e19f5c52d8122fa9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>█▇▆▆▅▅▄▃▃▂▂▁</td></tr><tr><td>val loss</td><td>█▆▅▃▂▂▂▁▁▂▄▇</td></tr><tr><td>weighted loss</td><td>▆▆█▅▃▂▄▅▃▂▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>0.27262</td></tr><tr><td>val loss</td><td>0.62335</td></tr><tr><td>weighted loss</td><td>0.24209</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</strong> at: <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/rcdenm2k' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/rcdenm2k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231001_182400-rcdenm2k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1269f5b972004fff92afcb60868ca987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668662211547294, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20231002_005928-jyzxzoxj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/jyzxzoxj' target=\"_blank\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</a></strong> to <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/jyzxzoxj' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/jyzxzoxj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:53<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:30<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "AUC score:  [0.68753611 0.56447265 0.58573917 0.66501035 0.70283584 0.64525037\n",
      " 0.63417469 0.57923375]\n",
      "2023-10-02 01:31:56 Eopch 1, Training Loss 0.7028079769527751, Val Loss 0.661520871216968, Weighted Loss 0.43362101878414966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:52<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:34<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "AUC score:  [0.74335644 0.63001511 0.67917222 0.72211557 0.68552789 0.65310506\n",
      " 0.66220333 0.68331843]\n",
      "2023-10-02 02:04:24 Eopch 2, Training Loss 0.6583787478270574, Val Loss 0.6328361799151211, Weighted Loss 0.3450630442656914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:53<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:35<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.         0.         0.09302326 0.10909091 0.26044226 0.\n",
      " 0.02197802 0.11764706]\n",
      "AUC score:  [0.7477253  0.68548806 0.65030222 0.70766046 0.71177384 0.80160776\n",
      " 0.69846618 0.64807692]\n",
      "2023-10-02 02:36:54 Eopch 3, Training Loss 0.6186850954066304, Val Loss 0.636518648468842, Weighted Loss 0.4267546746221116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:52<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:36<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.20289855 0.06521739 0.12637363 0.07751938 0.25891182 0.08\n",
      " 0.20444444 0.22325581]\n",
      "AUC score:  [0.80932265 0.73407072 0.72172933 0.75772633 0.71756091 0.72250859\n",
      " 0.72057478 0.77389684]\n",
      "2023-10-02 03:09:25 Eopch 4, Training Loss 0.5758065237785897, Val Loss 0.6189531717765129, Weighted Loss 0.44045138492188446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:52<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:36<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.13333333 0.125      0.09195402 0.17391304 0.3141994  0.0952381\n",
      " 0.20111732 0.16666667]\n",
      "AUC score:  [0.7918833  0.74051375 0.70533757 0.81261058 0.75453779 0.79356897\n",
      " 0.73875464 0.76560823]\n",
      "2023-10-02 03:41:56 Eopch 5, Training Loss 0.5369341819972744, Val Loss 0.5794388326547913, Weighted Loss 0.3225070371346227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:53<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:24<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.2173913  0.18032787 0.16       0.11111111 0.28436019 0.\n",
      " 0.11464968 0.28346457]\n",
      "AUC score:  [0.83679954 0.74441825 0.75172626 0.83628835 0.74357609 0.75613648\n",
      " 0.7322749  0.81110614]\n",
      "2023-10-02 04:14:15 Eopch 6, Training Loss 0.4991888412067928, Val Loss 0.5679041800104966, Weighted Loss 0.3206102932744319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:57<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:23<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.15189873 0.18461538 0.19753086 0.13636364 0.31724138 0.08333333\n",
      " 0.18604651 0.2244898 ]\n",
      "AUC score:  [0.83120306 0.73739498 0.78153878 0.83726708 0.74613234 0.80749877\n",
      " 0.72539691 0.77944246]\n",
      "2023-10-02 04:46:38 Eopch 7, Training Loss 0.45458875550167865, Val Loss 0.5832916634315152, Weighted Loss 0.28254308781709175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:53<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:34<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.20588235 0.21960784 0.12738854 0.1443299  0.30227743 0.04255319\n",
      " 0.22082019 0.23170732]\n",
      "AUC score:  [0.8136193  0.72875189 0.73580576 0.82864672 0.77339901 0.81817624\n",
      " 0.73839944 0.80864639]\n",
      "2023-10-02 05:19:07 Eopch 8, Training Loss 0.41614568268888674, Val Loss 0.5753563775602034, Weighted Loss 0.36126826266745493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:52<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:33<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.19354839 0.26190476 0.11881188 0.14814815 0.28571429 0.05263158\n",
      " 0.23966942 0.24193548]\n",
      "AUC score:  [0.82145436 0.72731339 0.72888024 0.84302654 0.75958816 0.80737604\n",
      " 0.7489048  0.79197973]\n",
      "2023-10-02 05:51:36 Eopch 9, Training Loss 0.3847345663487439, Val Loss 0.5840994170787981, Weighted Loss 0.293577582931967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:57<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:34<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.13461538 0.1971831  0.1        0.17021277 0.29333333 0.06666667\n",
      " 0.2202381  0.34210526]\n",
      "AUC score:  [0.82770075 0.72886068 0.76088516 0.83519669 0.75550526 0.76785714\n",
      " 0.71521447 0.84306798]\n",
      "2023-10-02 06:24:09 Eopch 10, Training Loss 0.34339403149111375, Val Loss 0.6045430273449017, Weighted Loss 0.28728700134108054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:54<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:33<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.14634146 0.22535211 0.171875   0.21238938 0.29916898 0.04255319\n",
      " 0.21621622 0.2739726 ]\n",
      "AUC score:  [0.8382799  0.70484134 0.7418912  0.85785808 0.75897572 0.78583702\n",
      " 0.71959529 0.81192606]\n",
      "2023-10-02 06:56:39 Eopch 11, Training Loss 0.30888712296169674, Val Loss 0.5869799765868712, Weighted Loss 0.34763251600522066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:53<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:26<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.20338983 0.23684211 0.12738854 0.19753086 0.3        0.0754717\n",
      " 0.23571429 0.33519553]\n",
      "AUC score:  [0.81463027 0.72961015 0.71437353 0.84434406 0.77614166 0.79860088\n",
      " 0.71167321 0.82938283]\n",
      "2023-10-02 07:29:00 Eopch 12, Training Loss 0.27639799103208257, Val Loss 0.5941863929821273, Weighted Loss 0.32313103889542555\n",
      "Finish training: best_val:0.5679041800104966, best_weighted loss:0.28254308781709175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>█▇▇▆▅▅▄▃▃▂▂▁</td></tr><tr><td>val loss</td><td>█▆▆▅▂▁▂▂▂▄▂▃</td></tr><tr><td>weighted loss</td><td>█▄▇█▃▃▁▄▁▁▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>0.2764</td></tr><tr><td>val loss</td><td>0.59419</td></tr><tr><td>weighted loss</td><td>0.32313</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</strong> at: <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/jyzxzoxj' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/jyzxzoxj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231002_005928-jyzxzoxj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21b821c177b4fd6bc6a5a5ccbfb25f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669257637113334, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20231002_072908-raad5mea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/raad5mea' target=\"_blank\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</a></strong> to <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/raad5mea' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/raad5mea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:55<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:19<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.         0.         0.         0.         0.10909091 0.\n",
      " 0.         0.        ]\n",
      "AUC score:  [0.66215919 0.54497958 0.63361917 0.52425121 0.63504771 0.7292011\n",
      " 0.62744691 0.58291555]\n",
      "2023-10-02 08:01:28 Eopch 1, Training Loss 0.6871051449514083, Val Loss 0.6770173975471723, Weighted Loss 0.39052474032701756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:55<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:37<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.24       0.05263158 0.03571429 0.04580153 0.19178082 0.\n",
      " 0.20547945 0.14876033]\n",
      "AUC score:  [0.73012313 0.62753938 0.71644679 0.57455717 0.65109136 0.7566706\n",
      " 0.66751977 0.72590272]\n",
      "2023-10-02 08:34:03 Eopch 2, Training Loss 0.6343855618655142, Val Loss 0.6617109271429353, Weighted Loss 0.4469973246718072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:52<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:24<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.125      0.09876543 0.14285714 0.11111111 0.21052632 0.\n",
      " 0.15       0.25454545]\n",
      "AUC score:  [0.79487687 0.63578741 0.72966139 0.67848631 0.673681   0.84978355\n",
      " 0.70476816 0.77363474]\n",
      "2023-10-02 09:06:21 Eopch 3, Training Loss 0.5985044510824378, Val Loss 0.6218104404160532, Weighted Loss 0.3549195691875008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:54<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:25<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.24390244 0.18045113 0.15151515 0.07446809 0.20216606 0.13793103\n",
      " 0.25454545 0.29959514]\n",
      "AUC score:  [0.7657212  0.66315706 0.72867194 0.71285024 0.68000915 0.79996065\n",
      " 0.76407046 0.83552671]\n",
      "2023-10-02 09:38:42 Eopch 4, Training Loss 0.5614227701265079, Val Loss 0.6325238530161017, Weighted Loss 0.449982470771754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [29:00<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:21<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.1682243  0.19       0.13821138 0.14516129 0.25613079 0.12121212\n",
      " 0.28104575 0.37234043]\n",
      "AUC score:  [0.80072559 0.67694797 0.75848725 0.80193237 0.7053762  0.83325462\n",
      " 0.77861935 0.84888093]\n",
      "2023-10-02 10:11:06 Eopch 5, Training Loss 0.5175992300506361, Val Loss 0.5916816701323299, Weighted Loss 0.37951242733862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:59<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:31<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.16666667 0.20740741 0.15189873 0.13333333 0.2484472  0.\n",
      " 0.19875776 0.39285714]\n",
      "AUC score:  [0.81332454 0.690898   0.75780563 0.80869565 0.71808696 0.81180638\n",
      " 0.75994328 0.85013429]\n",
      "2023-10-02 10:43:39 Eopch 6, Training Loss 0.4824025288510781, Val Loss 0.6148480744053751, Weighted Loss 0.2665382193413572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:57<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:37<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.18421053 0.15873016 0.19148936 0.16071429 0.24725275 0.06896552\n",
      " 0.29508197 0.425     ]\n",
      "AUC score:  [0.82282322 0.65134196 0.7748241  0.82657005 0.71982965 0.85548996\n",
      " 0.75283023 0.85502835]\n",
      "2023-10-02 11:16:15 Eopch 7, Training Loss 0.4401513392956953, Val Loss 0.5965412277538897, Weighted Loss 0.3030272513884402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:57<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:46<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.27536232 0.21052632 0.15544041 0.13496933 0.19964349 0.07017544\n",
      " 0.26344086 0.40191388]\n",
      "AUC score:  [0.817854   0.6685806  0.7994723  0.7989694  0.70668322 0.83081464\n",
      " 0.76810542 0.87912563]\n",
      "2023-10-02 11:49:00 Eopch 8, Training Loss 0.40936375668955066, Val Loss 0.5982483788440793, Weighted Loss 0.4048062782540054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:53<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [03:36<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.25641026 0.17313433 0.16736402 0.13333333 0.19650655 0.16393443\n",
      " 0.22540984 0.31782946]\n",
      "AUC score:  [0.81578716 0.65937782 0.79371152 0.7821256  0.69908073 0.82542306\n",
      " 0.76207604 0.89055506]\n",
      "2023-10-02 12:21:31 Eopch 9, Training Loss 0.375929304942219, Val Loss 0.6109682053074998, Weighted Loss 0.42371163637510334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [29:00<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [04:35<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.24705882 0.18627451 0.13513514 0.15311005 0.24404762 0.1025641\n",
      " 0.24355972 0.37168142]\n",
      "AUC score:  [0.84373351 0.63698085 0.78049692 0.79806763 0.71120333 0.87866982\n",
      " 0.75578151 0.87693226]\n",
      "2023-10-02 12:55:08 Eopch 10, Training Loss 0.334140787769227, Val Loss 0.6059734647051763, Weighted Loss 0.37262667610875716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:57<00:00,  1.97s/it]\n",
      "100%|██████████| 295/295 [03:44<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.18867925 0.21276596 0.11111111 0.         0.24561404 0.10526316\n",
      " 0.20430108 0.464     ]\n",
      "AUC score:  [0.82324099 0.65066568 0.76270888 0.79275362 0.70171655 0.80716253\n",
      " 0.72091951 0.8515667 ]\n",
      "2023-10-02 13:27:52 Eopch 11, Training Loss 0.30283181161969497, Val Loss 0.7034354956473334, Weighted Loss 0.25811512151588256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 884/884 [28:56<00:00,  1.96s/it]\n",
      "100%|██████████| 295/295 [04:11<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  [0.16949153 0.2556391  0.12121212 0.13636364 0.26627219 0.14035088\n",
      " 0.21290323 0.39506173]\n",
      "AUC score:  [0.82689094 0.64597146 0.74023747 0.80637681 0.70319784 0.82089728\n",
      " 0.72798644 0.88340794]\n",
      "2023-10-02 14:01:01 Eopch 12, Training Loss 0.2698209661762841, Val Loss 0.6542712587547505, Weighted Loss 0.3025703747603121\n",
      "Finish training: best_val:0.5916816701323299, best_weighted loss:0.25811512151588256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>█▇▇▆▅▅▄▃▃▂▂▁</td></tr><tr><td>val loss</td><td>▆▅▃▄▁▂▁▁▂▂█▅</td></tr><tr><td>weighted loss</td><td>▆█▅█▅▁▃▆▇▅▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>0.26982</td></tr><tr><td>val loss</td><td>0.65427</td></tr><tr><td>weighted loss</td><td>0.30257</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FullVol2.5Dx2_Effnetv2_15s_8class_posweight</strong> at: <a href='https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/raad5mea' target=\"_blank\">https://wandb.ai/rsna2023/FullVol2.5Dx2-test/runs/raad5mea</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231002_072908-raad5mea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = FullVolNet(backbone=backbone, ch_out = 8).to(device)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-5)\n",
    "TrainClassifer(model=net,trn_dl=train_dl_fold1,val_dl=val_dl_fold1,optimizer=optimizer, \n",
    "               project=project, name=name, suffix='fold1', scheduler=None, n_eopchs=n_eopchs, device=device)\n",
    "\n",
    "net = FullVolNet(backbone=backbone, ch_out = 8).to(device)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-5)\n",
    "TrainClassifer(model=net,trn_dl=train_dl_fold2,val_dl=val_dl_fold2,optimizer=optimizer, \n",
    "               project=project, name=name, suffix='fold2', scheduler=None, n_eopchs=n_eopchs, device=device)\n",
    "\n",
    "net = FullVolNet(backbone=backbone, ch_out = 8).to(device)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-5)\n",
    "TrainClassifer(model=net,trn_dl=train_dl_fold3,val_dl=val_dl_fold3,optimizer=optimizer, \n",
    "               project=project, name=name, suffix='fold3', scheduler=None, n_eopchs=n_eopchs, device=device)\n",
    "\n",
    "net = FullVolNet(backbone=backbone, ch_out = 8).to(device)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-5)\n",
    "TrainClassifer(model=net,trn_dl=train_dl_fold4,val_dl=val_dl_fold4,optimizer=optimizer, \n",
    "               project=project, name=name, suffix='fold4', scheduler=None, n_eopchs=n_eopchs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "732ea298-acdd-451a-8881-b6f393a121e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #net = FullVolNet(backbone = 'convnextv2_nano.fcmae_ft_in22k_in1k_384', ch_out = 8, slices=15).to(device)\n",
    "# net = FullVolNet(ch_out = 8, slices=15).to(device)\n",
    "\n",
    "# optimizer = optim.AdamW(net.parameters(), lr=1e-5)\n",
    "# TrainClassifer(model=net,trn_dl=train_dl,val_dl=val_dl,optimizer=optimizer, \n",
    "#                scheduler=None, n_eopchs=15, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea3821-71ab-4773-84c4-cacfabba3cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
